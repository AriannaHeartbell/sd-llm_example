{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AriannaHeartbell/sd-llm_example/blob/main/kohya-LoRA-trainer-XL_custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "\n",
        "# **Kohya LoRA Trainer XL**\n",
        "A Colab Notebook For SDXL LoRA Training (Fine-tuning Method)\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Kohya%20LoRA%20Trainer%20XL&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Kohya%20LoRA%20Trainer%20XL\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MxF9feWshAp"
      },
      "source": [
        "| Notebook Name | Description | Link |\n",
        "| --- | --- | --- |\n",
        "| [Kohya LoRA Trainer XL](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-trainer-XL.ipynb) | LoRA Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-trainer-XL.ipynb) |\n",
        "| [Kohya Trainer XL](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer-XL.ipynb) | Native Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer-XL.ipynb) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIbwGFkJ0nTx"
      },
      "source": [
        "<hr>\n",
        "<h4><font color=\"#4a90e2\"><b>NEWS:</b></font> <i>Colab's free-tier users can now train SDXL LoRA using the diffusers format instead of checkpoint as a pretrained model.</i></h4>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# **I. Prepare Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "_u3q60di584x",
        "outputId": "30ab1343-5463-44b9-cc0c-cb374005e1b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/kohya-trainer'...\n",
            "remote: Enumerating objects: 2441, done.\u001b[K\n",
            "remote: Counting objects: 100% (2441/2441), done.\u001b[K\n",
            "remote: Compressing objects: 100% (941/941), done.\u001b[K\n",
            "remote: Total 2441 (delta 1633), reused 2168 (delta 1497), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2441/2441), 4.12 MiB | 14.94 MiB/s, done.\n",
            "Resolving deltas: 100% (1633/1633), done.\n",
            "Mounted at /content/drive\n",
            "Cloning into '/content/repositories/infinite-image-browsing'...\n",
            "remote: Enumerating objects: 8404, done.\u001b[K\n",
            "remote: Counting objects: 100% (2800/2800), done.\u001b[K\n",
            "remote: Compressing objects: 100% (798/798), done.\u001b[K\n",
            "remote: Total 8404 (delta 2160), reused 2497 (delta 1946), pack-reused 5604\u001b[K\n",
            "Receiving objects: 100% (8404/8404), 18.84 MiB | 21.65 MiB/s, done.\n",
            "Resolving deltas: 100% (6044/6044), done.\n",
            "Cloning into '/content/repositories/discordia-archivum'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 54 (delta 26), reused 21 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (54/54), 16.04 KiB | 5.34 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for discord-protos (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2 lz4\n",
            "0 upgraded, 4 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 1,603 kB of archives.\n",
            "After this operation, 5,676 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.2 [45.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 lz4 amd64 1.9.3-2build2 [90.0 kB]\n",
            "Fetched 1,603 kB in 1s (1,127 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121730 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Selecting previously unselected package lz4.\n",
            "Preparing to unpack .../lz4_1.9.3-2build2_amd64.deb ...\n",
            "Unpacking lz4 (1.9.3-2build2) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up lz4 (1.9.3-2build2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "--2024-02-01 07:15:41--  https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/669786276/620e2e64-be9f-4599-904f-18ee3811e159?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240201T071541Z&X-Amz-Expires=300&X-Amz-Signature=5eb9a5dd15f247f5216c64d47c67d7cf43fcde47477f04940bf751b6300bcb94&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=669786276&response-content-disposition=attachment%3B%20filename%3Dlibtcmalloc_minimal.so.4&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-02-01 07:15:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/669786276/620e2e64-be9f-4599-904f-18ee3811e159?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240201T071541Z&X-Amz-Expires=300&X-Amz-Signature=5eb9a5dd15f247f5216c64d47c67d7cf43fcde47477f04940bf751b6300bcb94&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=669786276&response-content-disposition=attachment%3B%20filename%3Dlibtcmalloc_minimal.so.4&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 373960 (365K) [application/octet-stream]\n",
            "Saving to: ‘/content/libtcmalloc_minimal.so.4’\n",
            "\n",
            "/content/libtcmallo 100%[===================>] 365.20K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-02-01 07:15:41 (16.1 MB/s) - ‘/content/libtcmalloc_minimal.so.4’ saved [373960/373960]\n",
            "\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.8/495.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.7/624.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.0/204.0 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for elfinder-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title ## **1.1. Install Kohya Trainer**\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "import requests\n",
        "import torch\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root_dir\n",
        "root_dir          = \"/content\"\n",
        "drive_dir         = os.path.join(root_dir, \"drive/MyDrive\")\n",
        "deps_dir          = os.path.join(root_dir, \"deps\")\n",
        "repo_dir          = os.path.join(root_dir, \"kohya-trainer\")\n",
        "training_dir      = os.path.join(root_dir, \"LoRA\")\n",
        "pretrained_model  = os.path.join(root_dir, \"pretrained_model\")\n",
        "vae_dir           = os.path.join(root_dir, \"vae\")\n",
        "lora_dir          = os.path.join(root_dir, \"network_weight\")\n",
        "repositories_dir  = os.path.join(root_dir, \"repositories\")\n",
        "config_dir        = os.path.join(training_dir, \"config\")\n",
        "tools_dir         = os.path.join(repo_dir, \"tools\")\n",
        "finetune_dir      = os.path.join(repo_dir, \"finetune\")\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "for store in [\"root_dir\", \"repo_dir\", \"training_dir\", \"pretrained_model\", \"vae_dir\", \"repositories_dir\", \"accelerate_config\", \"tools_dir\", \"finetune_dir\", \"config_dir\"]:\n",
        "    with capture.capture_output() as cap:\n",
        "        %store {store}\n",
        "        del cap\n",
        "\n",
        "repo_dict = {\n",
        "    \"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\" : \"https://github.com/qaneel/kohya-trainer\",\n",
        "    \"kohya-ss/sd-scripts (original repo, latest update)\"                    : \"https://github.com/kohya-ss/sd-scripts\",\n",
        "}\n",
        "\n",
        "repository        = \"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\" #@param [\"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\", \"kohya-ss/sd-scripts (original repo, latest update)\"] {allow-input: true}\n",
        "repo_url          = repo_dict[repository]\n",
        "branch            = \"main\"  # @param {type: \"string\"}\n",
        "output_to_drive   = True  # @param {type: \"boolean\"}\n",
        "\n",
        "def clone_repo(url, dir, branch):\n",
        "    if not os.path.exists(dir):\n",
        "       !git clone -b {branch} {url} {dir}\n",
        "\n",
        "def mount_drive(dir):\n",
        "    output_dir      = os.path.join(training_dir, \"output\")\n",
        "\n",
        "    if output_to_drive:\n",
        "        if not os.path.exists(drive_dir):\n",
        "            drive.mount(os.path.dirname(drive_dir))\n",
        "        output_dir  = os.path.join(drive_dir, \"kohya-trainer/output\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    global output_dir\n",
        "\n",
        "    output_dir      = mount_drive(drive_dir)\n",
        "\n",
        "    for dir in [training_dir, config_dir, pretrained_model, vae_dir, repositories_dir, output_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def pastebin_reader(id):\n",
        "    if \"pastebin.com\" in id:\n",
        "        url = id\n",
        "        if 'raw' not in url:\n",
        "                url = url.replace('pastebin.com', 'pastebin.com/raw')\n",
        "    else:\n",
        "        url = \"https://pastebin.com/raw/\" + id\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    lines = response.text.split('\\n')\n",
        "    return lines\n",
        "\n",
        "def install_repository():\n",
        "    global infinite_image_browser_dir, voldy, discordia_archivum_dir\n",
        "\n",
        "    _, voldy = pastebin_reader(\"kq6ZmHFU\")[:2]\n",
        "\n",
        "    infinite_image_browser_url  = f\"https://github.com/zanllp/{voldy}-infinite-image-browsing.git\"\n",
        "    infinite_image_browser_dir  = os.path.join(repositories_dir, f\"infinite-image-browsing\")\n",
        "    infinite_image_browser_deps = os.path.join(infinite_image_browser_dir, \"requirements.txt\")\n",
        "\n",
        "    discordia_archivum_url = \"https://github.com/Linaqruf/discordia-archivum\"\n",
        "    discordia_archivum_dir = os.path.join(repositories_dir, \"discordia-archivum\")\n",
        "    discordia_archivum_deps = os.path.join(discordia_archivum_dir, \"requirements.txt\")\n",
        "\n",
        "    clone_repo(infinite_image_browser_url, infinite_image_browser_dir, \"main\")\n",
        "    clone_repo(discordia_archivum_url, discordia_archivum_dir, \"main\")\n",
        "\n",
        "    !pip install -q --upgrade -r {infinite_image_browser_deps}\n",
        "    !pip install python-dotenv\n",
        "    !pip install -q --upgrade -r {discordia_archivum_deps}\n",
        "\n",
        "def install_dependencies():\n",
        "    requirements_file = os.path.join(repo_dir, \"requirements.txt\")\n",
        "    model_util        = os.path.join(repo_dir, \"library/model_util.py\")\n",
        "    gpu_info          = getoutput('nvidia-smi')\n",
        "    t4_xformers_wheel = \"https://github.com/Linaqruf/colab-xformers/releases/download/0.0.20/xformers-0.0.20+1d635e1.d20230519-cp310-cp310-linux_x86_64.whl\"\n",
        "\n",
        "    !apt install aria2 lz4\n",
        "    !wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "    !pip install -q --upgrade -r {requirements_file}\n",
        "\n",
        "    !pip install -q xformers==0.0.22.post7\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "def prepare_environment():\n",
        "    os.environ[\"LD_PRELOAD\"] = \"/content/libtcmalloc_minimal.so.4\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "    clone_repo(repo_url, repo_dir, branch)\n",
        "    os.chdir(repo_dir)\n",
        "    setup_directories()\n",
        "    install_repository()\n",
        "    install_dependencies()\n",
        "    prepare_environment()\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wrYGu-WxFbsq",
        "outputId": "9f4cb1df-2744-47ea-bbe2-480d371521d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt to load diffusers model instead due to hardware constraints.\n",
            "Diffusers model is loaded : cagliostrolab/animagine-xl-3.0-base\n",
            "\n",
            "Starting downloading from https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\n",
            "Download finished: /content/vae/sdxl_vae.safetensors\n",
            "\n",
            "Selected model: cagliostrolab/animagine-xl-3.0-base\n",
            "Selected VAE: /content/vae/sdxl_vae.safetensors\n"
          ]
        }
      ],
      "source": [
        "# @title ## **1.2. Download SDXL**\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import glob\n",
        "import gdown\n",
        "import requests\n",
        "import subprocess\n",
        "from IPython.utils import capture\n",
        "from urllib.parse import urlparse, unquote\n",
        "from pathlib import Path\n",
        "from huggingface_hub import HfFileSystem\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Place your Huggingface token [here](https://huggingface.co/settings/tokens) to download gated models.\n",
        "\n",
        "HUGGINGFACE_TOKEN     = \"\" #@param {type: \"string\"}\n",
        "LOAD_DIFFUSERS_MODEL  = True #@param {type: \"boolean\"}\n",
        "SDXL_MODEL_URL        = \"cagliostrolab/animagine-xl-3.0-base\" # @param [\"gsdf/CounterfeitXL\", \"Linaqruf/animagine-xl\", \"cagliostrolab/animagine-xl-3.0-base\", \"PASTE MODEL URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "SDXL_VAE_URL          = \"Original VAE\" # @param [\"None\", \"Original VAE\", \"FP16 VAE\", \"PASTE VAE URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "\n",
        "MODEL_URLS = {\n",
        "    \"gsdf/CounterfeitXL\"        : \"https://huggingface.co/gsdf/CounterfeitXL/resolve/main/CounterfeitXL_%CE%B2.safetensors\",\n",
        "    \"Linaqruf/animagine-xl\"   : \"https://huggingface.co/Linaqruf/animagine-xl/resolve/main/animagine-xl.safetensors\",\n",
        "    \"cagliostrolab/animagine-xl-3.0-base\" : \"https://huggingface.co/cagliostrolab/animagine-xl-3.0-base/resolve/main/animagine-xl-3.0-base.safetensors?download=true\",\n",
        "}\n",
        "VAE_URLS = {\n",
        "    \"None\"                    : \"\",\n",
        "    \"Original VAE\"           : \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\",\n",
        "    \"FP16 VAE\"           : \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae.safetensors\"\n",
        "}\n",
        "\n",
        "SDXL_MODEL_URL = MODEL_URLS.get(SDXL_MODEL_URL, SDXL_MODEL_URL)\n",
        "SDXL_VAE_URL = VAE_URLS.get(SDXL_VAE_URL, SDXL_VAE_URL)\n",
        "\n",
        "def get_filename(url):\n",
        "    if any(url.endswith(ext) for ext in [\".ckpt\", \".safetensors\", \".pt\", \".pth\"]):\n",
        "        return os.path.basename(url)\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    if 'content-disposition' in response.headers:\n",
        "        filename = re.findall('filename=\"?([^\"]+)\"?', response.headers['content-disposition'])[0]\n",
        "    else:\n",
        "        filename = unquote(os.path.basename(urlparse(url).path))\n",
        "\n",
        "    return filename\n",
        "\n",
        "def aria2_download(dir, filename, url):\n",
        "    user_header = f\"Authorization: Bearer {HUGGINGFACE_TOKEN}\"\n",
        "    aria2_args = [\n",
        "        \"aria2c\",\n",
        "        \"--console-log-level=error\",\n",
        "        \"--summary-interval=10\",\n",
        "        f\"--header={user_header}\" if \"huggingface.co\" in url else \"\",\n",
        "        \"--continue=true\",\n",
        "        \"--max-connection-per-server=16\",\n",
        "        \"--min-split-size=1M\",\n",
        "        \"--split=16\",\n",
        "        f\"--dir={dir}\",\n",
        "        f\"--out={filename}\",\n",
        "        url\n",
        "    ]\n",
        "    subprocess.run(aria2_args)\n",
        "\n",
        "def download(url, dst):\n",
        "    print(f\"Starting downloading from {url}\")\n",
        "    filename = get_filename(url)\n",
        "    filepath = os.path.join(dst, filename)\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        gdown.download(url, filepath, quiet=False)\n",
        "    else:\n",
        "        if \"huggingface.co\" in url and \"/blob/\" in url:\n",
        "            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "        aria2_download(dst, filename, url)\n",
        "\n",
        "    print(f\"Download finished: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "def all_folders_present(base_model_url, sub_folders):\n",
        "    fs = HfFileSystem()\n",
        "    existing_folders = set(fs.ls(base_model_url, detail=False))\n",
        "\n",
        "    for folder in sub_folders:\n",
        "        full_folder_path = f\"{base_model_url}/{folder}\"\n",
        "        if full_folder_path not in existing_folders:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def get_total_ram_gb():\n",
        "    with open('/proc/meminfo', 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            if \"MemTotal\" in line:\n",
        "                return int(line.split()[1]) / (1024**2)  # Convert to GB\n",
        "\n",
        "def get_gpu_name():\n",
        "    try:\n",
        "        return subprocess.check_output(\"nvidia-smi --query-gpu=name --format=csv,noheader,nounits\", shell=True).decode('ascii').strip()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    global model_path, vae_path, LOAD_DIFFUSERS_MODEL\n",
        "\n",
        "    model_path, vae_path = None, None\n",
        "\n",
        "    required_sub_folders = [\n",
        "        'scheduler',\n",
        "        'text_encoder',\n",
        "        'text_encoder_2',\n",
        "        'tokenizer',\n",
        "        'tokenizer_2',\n",
        "        'unet',\n",
        "        'vae',\n",
        "    ]\n",
        "\n",
        "    download_targets = {\n",
        "        \"model\": (SDXL_MODEL_URL, pretrained_model),\n",
        "        \"vae\": (SDXL_VAE_URL, vae_dir),\n",
        "    }\n",
        "\n",
        "    total_ram = get_total_ram_gb()\n",
        "    gpu_name = get_gpu_name()\n",
        "\n",
        "    # Check hardware constraints\n",
        "    if total_ram < 13 and gpu_name in [\"Tesla T4\", \"Tesla V100\"]:\n",
        "        print(\"Attempt to load diffusers model instead due to hardware constraints.\")\n",
        "        if not LOAD_DIFFUSERS_MODEL:\n",
        "            LOAD_DIFFUSERS_MODEL = True\n",
        "\n",
        "    for target, (url, dst) in download_targets.items():\n",
        "        if url and not url.startswith(f\"PASTE {target.upper()} URL OR GDRIVE PATH HERE\"):\n",
        "            if target == \"model\" and LOAD_DIFFUSERS_MODEL:\n",
        "                # Code for checking and handling diffusers model\n",
        "                if 'huggingface.co' in url:\n",
        "                    match = re.search(r'huggingface\\.co/([^/]+)/([^/]+)', SDXL_MODEL_URL)\n",
        "                    if match:\n",
        "                        username = match.group(1)\n",
        "                        model_name = match.group(2)\n",
        "                        url = f\"{username}/{model_name}\"\n",
        "                if all_folders_present(url, required_sub_folders):\n",
        "                    print(f\"Diffusers model is loaded : {url}\")\n",
        "                    model_path = url\n",
        "                else:\n",
        "                    print(\"Repository doesn't exist or no diffusers model detected.\")\n",
        "                    filepath = download(url, dst)  # Continue with the regular download\n",
        "                    model_path = filepath\n",
        "            else:\n",
        "                filepath = download(url, dst)\n",
        "\n",
        "                if target == \"model\":\n",
        "                    model_path = filepath\n",
        "                elif target == \"vae\":\n",
        "                    vae_path = filepath\n",
        "\n",
        "            print()\n",
        "\n",
        "    if model_path:\n",
        "        print(f\"Selected model: {model_path}\")\n",
        "\n",
        "    if vae_path:\n",
        "        print(f\"Selected VAE: {vae_path}\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "kh7CeDqK4l3Y",
        "outputId": "a4e552de-d732-4333-8a2d-6430ab2da360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'train_data_dir' (str)\n",
            "Your train data directory : /content/LoRA/train_data\n"
          ]
        }
      ],
      "source": [
        "# @title ## **1.3. Directory Config**\n",
        "# @markdown Specify the location of your training data in the following cell. A folder with the same name as your input will be created.\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "train_data_dir = \"/content/LoRA/train_data\"  # @param {'type' : 'string'}\n",
        "%store train_data_dir\n",
        "\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "print(f\"Your train data directory : {train_data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qqUYtRn0RPoK"
      },
      "outputs": [],
      "source": [
        "# @title ## **1.4. Image Browser**\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import portpicker\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from threading import Thread\n",
        "from imjoy_elfinder.app import main\n",
        "from google.colab.output import serve_kernel_port_as_iframe, serve_kernel_port_as_window\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown This cell allows you to view and manage your images in real-time. You can use it to:\n",
        "# @markdown - Prepare your dataset before training\n",
        "# @markdown - Monitor the sample outputs during training.\n",
        "\n",
        "root_dir      = \"/content\"\n",
        "browser_type  = \"infinite-image-browsing\" #@param [\"imjoy-elfinder\", \"infinite-image-browsing\"]\n",
        "window_height = 550 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "main_app          = os.path.join(infinite_image_browser_dir, \"app.py\")\n",
        "config_file       = os.path.join(infinite_image_browser_dir, \"config.json\")\n",
        "port              = portpicker.pick_unused_port()\n",
        "\n",
        "config = {\n",
        "    \"outdir_txt2img_samples\": train_data_dir,\n",
        "}\n",
        "\n",
        "def write_file(filename, config):\n",
        "    with open(filename, 'w',) as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "def run_app():\n",
        "    !python {main_app} --port={port} --sd_webui_config={config_file} > /dev/null 2>&1\n",
        "\n",
        "def launch():\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "    thread = Thread(target=main, args=[[f\"--root-dir={root_dir}\",\n",
        "                                        f\"--port={port}\",\n",
        "                                        f\"--thumbnail\"]])\n",
        "\n",
        "    if browser_type == \"infinite-image-browsing\":\n",
        "        os.chdir(train_data_dir)\n",
        "        write_file(config_file, config)\n",
        "\n",
        "        thread = Thread(target=run_app)\n",
        "\n",
        "    thread.start()\n",
        "\n",
        "    serve_kernel_port_as_iframe(port, width='100%', height=window_height, cache_in_notebook=False)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# **II. Data Gathering**\n",
        "\n",
        "You have three options for collecting your dataset:\n",
        "\n",
        "1. Upload it to Colab's local files.\n",
        "2. Use the `Simple Booru Scraper` to download images in bulk from Danbooru.\n",
        "3. Locate your dataset in Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t17ZfiMB8GWZ"
      },
      "outputs": [],
      "source": [
        "# @title ## **2.1. Unzip Dataset**\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import re\n",
        "from urllib.parse import unquote\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# @title ## Unzip Dataset\n",
        "# @markdown If your dataset is in a `zip` file and has been uploaded to a location, use this section to extract it.\n",
        "# @markdown The dataset will be downloaded and automatically extracted to `train_data_dir` if `unzip_to` is empty.\n",
        "\n",
        "zipfile_url = \"\"  # @param {type:\"string\"}\n",
        "unzip_to = \"\"  # @param {type:\"string\"}\n",
        "hf_token = \"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\"\n",
        "\n",
        "use_aria2c = True # @param {type:\"boolean\"}\n",
        "preserve_folders = True # @param {type:\"boolean\"}\n",
        "remove_after_unzipping = False # @param {type:\"boolean\"}\n",
        "\n",
        "if \"huggingface.co\" in zipfile_url and \"blob\" in zipfile_url:\n",
        "    zipfile_url = zipfile_url.replace(\"blob\", \"resolve\")\n",
        "\n",
        "if not unzip_to:\n",
        "    unzip_to = train_data_dir\n",
        "\n",
        "def get_filename_from_url(url):\n",
        "    if \"huggingface.co\" or \"/content/\" in url:\n",
        "        return os.path.basename(url)\n",
        "\n",
        "    response = requests.head(url, allow_redirects=True)\n",
        "    cd = response.headers.get('content-disposition')\n",
        "    if cd:\n",
        "        fname = re.findall('filename=(.+)', cd)\n",
        "        if len(fname) == 0:\n",
        "            return \"zipfile.zip\"\n",
        "        return unquote(fname[0])\n",
        "\n",
        "    return \"zipfile.zip\"\n",
        "\n",
        "def download_with_requests(url, output_path):\n",
        "    print(f\"Downloading {url} with requests...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(output_path, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "    print(f\"Downloaded to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def download_with_aria2c(url, output_path):\n",
        "    print(f\"Downloading {url} with aria2c...\")\n",
        "    aria_args = {\n",
        "        'console-log-level': 'error',\n",
        "        'summary-interval': '10',\n",
        "        'continue': 'true',\n",
        "        'max-connection-per-server': '16',\n",
        "        'min-split-size': '1M',\n",
        "        'split': '16',\n",
        "        'dir': os.path.dirname(output_path),\n",
        "        'out': os.path.basename(output_path),\n",
        "    }\n",
        "\n",
        "    if \"huggingface.co\" in url:\n",
        "        aria_args['header'] = f\"Authorization: Bearer {hf_token}\"\n",
        "\n",
        "    cmd = ['aria2c'] + [f'--{k}={v}' for k, v in aria_args.items()] + [url]\n",
        "    subprocess.run(cmd)\n",
        "    print(f\"Downloaded to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def move_files(train_dir):\n",
        "    for filename in os.listdir(train_dir):\n",
        "        file_path = os.path.join(train_dir, filename)\n",
        "        if filename.startswith(\"meta_\") and filename.endswith(\".json\"):\n",
        "            if not os.path.exists(file_path):\n",
        "                shutil.move(file_path, training_dir)\n",
        "            else:\n",
        "                os.remove(file_path)\n",
        "\n",
        "def remove_empty_dirs(path):\n",
        "    for dirpath, dirnames, files in os.walk(path, topdown=False):  # start from leaf folders\n",
        "        for dirname in dirnames:\n",
        "            full_dir_path = os.path.join(dirpath, dirname)\n",
        "            if not os.listdir(full_dir_path):  # Check if directory is empty\n",
        "                os.rmdir(full_dir_path)\n",
        "                print(f\"Removed empty directory: {full_dir_path}\")\n",
        "\n",
        "def extract_dataset(zip_file, output_path):\n",
        "    with ZipFile(zip_file, 'r') as zip_ref:\n",
        "        print(f\"Extracting {zip_file} to {output_path}...\")\n",
        "\n",
        "        if not preserve_folders:  # If we do not want to preserve folder structure\n",
        "            for member in zip_ref.namelist():\n",
        "                # Extract only the file name, discard directory structure\n",
        "                filename = os.path.basename(member)\n",
        "                if filename:  # Check if file name is not empty (this skips directories)\n",
        "                    zip_ref.extract(member, output_path)\n",
        "                    source_path = os.path.join(output_path, member)\n",
        "                    target_path = os.path.join(output_path, filename)\n",
        "                    os.rename(source_path, target_path)\n",
        "\n",
        "            remove_empty_dirs(output_path)\n",
        "\n",
        "        else:\n",
        "            zip_ref.extractall(output_path)\n",
        "\n",
        "        print(\"Extraction completed!\")\n",
        "\n",
        "def download_dataset(url, output_path):\n",
        "    if url.startswith(\"/content\"):\n",
        "        print(f\"Using file at {url}\")\n",
        "        return url\n",
        "\n",
        "    elif \"drive.google.com\" in url:\n",
        "        print(\"Downloading from Google Drive...\")\n",
        "        cmd = ['gdown', '--id', url.split('/')[-2], '-O', output_path]\n",
        "        subprocess.run(cmd)\n",
        "        return output_path\n",
        "\n",
        "    elif use_aria2c:\n",
        "        return download_with_aria2c(url, output_path)\n",
        "\n",
        "    else:\n",
        "        return download_with_requests(url, output_path)\n",
        "\n",
        "def main():\n",
        "    zipfile_name = get_filename_from_url(zipfile_url)\n",
        "    output_path = os.path.join(root_dir, zipfile_name)\n",
        "\n",
        "    zip_file = download_dataset(zipfile_url, output_path)\n",
        "\n",
        "    extract_dataset(zip_file, unzip_to)\n",
        "\n",
        "    move_files(unzip_to)\n",
        "\n",
        "    if remove_after_unzipping and \"/content/drive\" not in zip_file:\n",
        "        os.remove(zip_file)\n",
        "        print(f\"Removed {zip_file}\")\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A0t1dfnU5Xkq"
      },
      "outputs": [],
      "source": [
        "#@title ## **2.2. Imageboard Scraper**\n",
        "import os\n",
        "import html\n",
        "from IPython.utils import capture\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "#@markdown Use `gallery-dl` to scrape images from an imageboard site. To specify `prompt(s)`, separate them with commas (e.g., `hito_komoru, touhou`).\n",
        "booru = \"Danbooru\" #@param [\"Danbooru\", \"Gelbooru\", \"Safebooru\"]\n",
        "prompt = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Alternatively, you can provide a `custom_url` instead of using a predefined site.\n",
        "custom_url = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Use the `sub_folder` option to organize the downloaded images into separate folders based on their concept or category.\n",
        "sub_folder = \"\" #@param {type: \"string\"}\n",
        "\n",
        "user_agent = \"gdl/1.24.5\"\n",
        "\n",
        "#@markdown You can limit the number of images to download by using the `--range` option followed by the desired range (e.g., `1-200`).\n",
        "range = \"\" #@param {type: \"string\"}\n",
        "\n",
        "write_tags = False #@param {type: \"boolean\"}\n",
        "\n",
        "additional_arguments = \"--filename /O --no-part\"\n",
        "\n",
        "tags = prompt.split(',')\n",
        "tags = '+'.join(tags)\n",
        "\n",
        "replacement_dict = {\" \": \"\", \"(\": \"%28\", \")\": \"%29\", \":\": \"%3a\"}\n",
        "tags = ''.join(replacement_dict.get(c, c) for c in tags)\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "if booru == \"Danbooru\":\n",
        "    url = \"https://danbooru.donmai.us/posts?tags={}\".format(tags)\n",
        "elif booru == \"Gelbooru\":\n",
        "    url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "else:\n",
        "    url = \"https://safebooru.org/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "\n",
        "valid_url = custom_url if custom_url else url\n",
        "\n",
        "def scrape(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "def pre_process_tags(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        item_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(item_path) and item.endswith(\".txt\"):\n",
        "            old_path = item_path\n",
        "            new_file_name = os.path.splitext(os.path.splitext(item)[0])[0] + \".txt\"\n",
        "            new_path = os.path.join(directory, new_file_name)\n",
        "\n",
        "            os.rename(old_path, new_path)\n",
        "\n",
        "            with open(new_path, \"r\") as f:\n",
        "                contents = f.read()\n",
        "\n",
        "            contents = html.unescape(contents)\n",
        "            contents = contents.replace(\"_\", \" \")\n",
        "            contents = \", \".join(contents.split(\"\\n\"))\n",
        "\n",
        "            with open(new_path, \"w\") as f:\n",
        "                f.write(contents)\n",
        "\n",
        "        elif os.path.isdir(item_path):\n",
        "            pre_process_tags(item_path)\n",
        "\n",
        "get_url_config = {\n",
        "    \"_valid_url\" : valid_url,\n",
        "    \"get-urls\" : True,\n",
        "    \"range\" : range if range else None,\n",
        "    \"user-agent\" : user_agent\n",
        "}\n",
        "\n",
        "scrape_config = {\n",
        "    \"_valid_url\" : valid_url,\n",
        "    \"directory\" : image_dir,\n",
        "    \"write-tags\" : write_tags,\n",
        "    \"range\" : range if range else None,\n",
        "    \"user-agent\" : user_agent\n",
        "}\n",
        "\n",
        "get_url_args = scrape(get_url_config)\n",
        "scrape_args = scrape(scrape_config)\n",
        "scraper_text = os.path.join(root_dir, \"scrape_this.txt\")\n",
        "\n",
        "if write_tags:\n",
        "    !gallery-dl {scrape_args} {additional_arguments}\n",
        "    pre_process_tags(train_data_dir)\n",
        "else:\n",
        "    with capture.capture_output() as cap:\n",
        "        !gallery-dl {get_url_args} {additional_arguments}\n",
        "    with open(scraper_text, \"w\") as f:\n",
        "        f.write(cap.stdout)\n",
        "\n",
        "    os.chdir(image_dir)\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -i {scraper_text}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EVWk3PM2KKB7"
      },
      "outputs": [],
      "source": [
        "#@title ## **2.3. Journey Scraper**\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# @markdown Enter your Discord token below.\n",
        "token = \"\" #@param {type: \"string\"}\n",
        "channel_id = \"1022054094476673085\" #@param {type: \"string\"}\n",
        "# @markdown Which bot do you want to scrape? This code is optimized to only scrape non-grid images from the Journey bot, so don't worry about cropping.\n",
        "bot = \"niji\" #@param [\"niji\", \"mid\"]\n",
        "# @markdown Set the limit of messages to scrape here. (This does not limit the number of messages to download.)\n",
        "limit = 10000 #@param {type: \"number\"}\n",
        "# @markdown To specify the `include_word` and `undesired_word`, separate them with commas (e.g., hito_komoru, touhou). By default, it scrapes the newest Niji model.\n",
        "include_word = \"girl\" #@param {type:\"string\"}\n",
        "undesired_word = \"--style, --niji 4\" #@param {type:\"string\"}\n",
        "download_attachments = \"single\"\n",
        "\n",
        "def scrape(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "scrape_config = {\n",
        "    \"token\": token,\n",
        "    \"channel_id\": channel_id,\n",
        "    \"nijijourney\": True if bot == \"niji\" else False,\n",
        "    \"midjourney\": True if bot == \"mid\" else False,\n",
        "    \"limit\": limit if limit else None,\n",
        "    \"prompt\": include_word,\n",
        "    \"single\": True,\n",
        "    \"undesired_word\": undesired_word,\n",
        "    \"download_attachments\": True,\n",
        "    \"output_folder\": train_data_dir,\n",
        "\n",
        "}\n",
        "\n",
        "scrape_args = scrape(scrape_config)\n",
        "\n",
        "os.chdir(discordia_archivum_dir)\n",
        "!python main.py {scrape_args}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-0qKyEgTchp"
      },
      "source": [
        "# **III. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu"
      },
      "outputs": [],
      "source": [
        "# @title ## **3.1. Data Cleaning**\n",
        "import os\n",
        "import random\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "#@markdown This section removes unsupported media types such as `.mp4`, `.webm`, and `.gif`, as well as any unnecessary files.\n",
        "#@markdown To convert a transparent dataset with an alpha channel (RGBA) to RGB and give it a white background, set the `convert` parameter to `True`.\n",
        "convert = False  # @param {type:\"boolean\"}\n",
        "#@markdown Alternatively, you can give the background a `random_color` instead of white by checking the corresponding option.\n",
        "random_color = False  # @param {type:\"boolean\"}\n",
        "recursive = False\n",
        "\n",
        "batch_size = 32\n",
        "supported_types = [\n",
        "    \".png\",\n",
        "    \".jpg\",\n",
        "    \".jpeg\",\n",
        "    \".webp\",\n",
        "    \".bmp\",\n",
        "    \".caption\",\n",
        "    \".npz\",\n",
        "    \".txt\",\n",
        "    \".json\",\n",
        "]\n",
        "\n",
        "background_colors = [\n",
        "    (255, 255, 255),\n",
        "    (0, 0, 0),\n",
        "    (255, 0, 0),\n",
        "    (0, 255, 0),\n",
        "    (0, 0, 255),\n",
        "    (255, 255, 0),\n",
        "    (255, 0, 255),\n",
        "    (0, 255, 255),\n",
        "]\n",
        "\n",
        "def clean_directory(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(file_path):\n",
        "            file_ext = os.path.splitext(item)[1]\n",
        "            if file_ext not in supported_types:\n",
        "                print(f\"Deleting file {item} from {directory}\")\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path) and recursive:\n",
        "            clean_directory(file_path)\n",
        "\n",
        "def process_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img_dir, image_name = os.path.split(image_path)\n",
        "\n",
        "    if img.mode in (\"RGBA\", \"LA\"):\n",
        "        if random_color:\n",
        "            background_color = random.choice(background_colors)\n",
        "        else:\n",
        "            background_color = (255, 255, 255)\n",
        "        bg = Image.new(\"RGB\", img.size, background_color)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            bg = bg.convert(\"RGB\")\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            bg.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            bg.save(image_path, \"PNG\")\n",
        "            print(f\" Converted image: {image_name}\")\n",
        "    else:\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            img.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            img.save(image_path, \"PNG\")\n",
        "\n",
        "def find_images(directory):\n",
        "    images = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\") or file.endswith(\".webp\"):\n",
        "                images.append(os.path.join(root, file))\n",
        "    return images\n",
        "\n",
        "clean_directory(train_data_dir)\n",
        "images = find_images(train_data_dir)\n",
        "num_batches = len(images) // batch_size + 1\n",
        "\n",
        "if convert:\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        for i in tqdm(range(num_batches)):\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "            batch = images[start:end]\n",
        "            executor.map(process_image, batch)\n",
        "\n",
        "    print(\"All images have been converted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdISafLeyklg"
      },
      "source": [
        "## **3.2. Data Captioning**\n",
        "\n",
        "- For general images, use BLIP captioning.\n",
        "- For anime and manga-style images, use Waifu Diffusion 1.4 Tagger V2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nvPyH-G_Qdha"
      },
      "outputs": [],
      "source": [
        "#@title ### **3.2.1. BLIP Captioning**\n",
        "#@markdown BLIP is a pre-training framework for unified vision-language understanding and generation, which achieves state-of-the-art results on a wide range of vision-language tasks. It can be used as a tool for image captioning, for example, `astronaut riding a horse in space`.\n",
        "import os\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "beam_search = True #@param {type:'boolean'}\n",
        "min_length = 5 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "max_length = 75 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"   : train_data_dir,\n",
        "    \"batch_size\"        : 8,\n",
        "    \"beam_search\"       : beam_search,\n",
        "    \"min_length\"        : min_length,\n",
        "    \"max_length\"        : max_length,\n",
        "    \"debug\"             : True,\n",
        "    \"caption_extension\" : \".caption\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"recursive\"         : True\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python make_captions.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-BdXV7rAy2ag"
      },
      "outputs": [],
      "source": [
        "#@title ### **3.2.2. Waifu Diffusion 1.4 Tagger V2**\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "#@markdown [Waifu Diffusion 1.4 Tagger V2](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) is a Danbooru-styled image classification model developed by SmilingWolf. It can also be useful for general image tagging, for example, `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background`.\n",
        "model = \"SmilingWolf/wd-v1-4-moat-tagger-v2\" #@param [\"SmilingWolf/wd-v1-4-moat-tagger-v2\", \"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\", \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\", \"SmilingWolf/wd-v1-4-convnext-tagger-v2\", \"SmilingWolf/wd-v1-4-vit-tagger-v2\"]\n",
        "#@markdown Separate `undesired_tags` with comma `(,)` if you want to remove multiple tags, e.g. `1girl,solo,smile`.\n",
        "undesired_tags = \"\" #@param {type:'string'}\n",
        "#@markdown Adjust `general_threshold` for pruning tags (less tags, less flexible). `character_threshold` is useful if you want to train with character tags, e.g. `hakurei reimu`.\n",
        "general_threshold = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "character_threshold = 0.85 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"           : train_data_dir,\n",
        "    \"batch_size\"                : 8,\n",
        "    \"repo_id\"                   : model,\n",
        "    \"recursive\"                 : True,\n",
        "    \"remove_underscore\"         : True,\n",
        "    \"general_threshold\"         : general_threshold,\n",
        "    \"character_threshold\"       : character_threshold,\n",
        "    \"caption_extension\"         : \".txt\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"debug\"                     : True,\n",
        "    \"undesired_tags\"            : undesired_tags\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python tag_images_by_wd14_tagger.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "_mLVURhM9PFE"
      },
      "outputs": [],
      "source": [
        "# @title ### **3.2.3. Custom Caption/Tag**\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Add or remove custom tags here.\n",
        "extension   = \".txt\"  # @param [\".txt\", \".caption\"]\n",
        "custom_tag  = \"anime coloring\"  # @param {type:\"string\"}\n",
        "# @markdown Use `sub_folder` option to specify a subfolder for multi-concept training.\n",
        "# @markdown > Specify `--all` to process all subfolders/`recursive`\n",
        "sub_folder  = \"--all\" #@param {type: \"string\"}\n",
        "# @markdown Enable this to append custom tags at the end of lines.\n",
        "append      = True  # @param {type:\"boolean\"}\n",
        "# @markdown Enable this if you want to remove captions/tags instead.\n",
        "remove_tag  = False  # @param {type:\"boolean\"}\n",
        "recursive   = False\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder == \"--all\":\n",
        "    image_dir = train_data_dir\n",
        "    recursive = True\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def process_tags(filename, custom_tag, append, remove_tag):\n",
        "    contents = read_file(filename)\n",
        "    tags = [tag.strip() for tag in contents.split(',')]\n",
        "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
        "\n",
        "    for custom_tag in custom_tags:\n",
        "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
        "        if remove_tag:\n",
        "            while custom_tag in tags:\n",
        "                tags.remove(custom_tag)\n",
        "        else:\n",
        "            if custom_tag not in tags:\n",
        "                if append:\n",
        "                    tags.append(custom_tag)\n",
        "                else:\n",
        "                    tags.insert(0, custom_tag)\n",
        "\n",
        "    contents = ', '.join(tags)\n",
        "    write_file(filename, contents)\n",
        "\n",
        "def process_directory(image_dir, tag, append, remove_tag, recursive):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "\n",
        "        if os.path.isdir(file_path) and recursive:\n",
        "            process_directory(file_path, tag, append, remove_tag, recursive)\n",
        "        elif filename.endswith(extension):\n",
        "            process_tags(file_path, tag, append, remove_tag)\n",
        "\n",
        "tag = custom_tag\n",
        "\n",
        "if not any(\n",
        "    [filename.endswith(extension) for filename in os.listdir(image_dir)]\n",
        "):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")):\n",
        "            open(\n",
        "                os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
        "                \"w\",\n",
        "            ).close()\n",
        "\n",
        "if custom_tag:\n",
        "    process_directory(image_dir, tag, append, remove_tag, recursive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "hhgatqF3leHJ",
        "outputId": "86b6439b-fa52-4f71-bab2-f9854d8195b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 61 images.\n",
            "Creating a new metadata file\n",
            "Merging tags and captions into metadata json.\n",
            "\r  0% 0/61 [00:00<?, ?it/s]\r100% 61/61 [00:00<00:00, 9400.12it/s]\n",
            "60/61 images have captions\n",
            "All 61 images have tags\n",
            "Writing metadata: /content/LoRA/meta_clean.json\n",
            "Done!\n",
            "found 61 images.\n",
            "loading existing metadata: /content/LoRA/meta_clean.json\n",
            "load VAE: /content/vae/sdxl_vae.safetensors\n",
            "100% 61/61 [00:30<00:00,  1.99it/s]\n",
            "bucket 0 (384, 1024): 1\n",
            "bucket 1 (512, 1024): 1\n",
            "bucket 2 (576, 1024): 1\n",
            "bucket 3 (640, 1024): 1\n",
            "bucket 4 (704, 1024): 3\n",
            "bucket 5 (832, 1024): 1\n",
            "bucket 6 (896, 1024): 2\n",
            "bucket 7 (960, 1024): 3\n",
            "bucket 8 (1024, 512): 1\n",
            "bucket 9 (1024, 576): 35\n",
            "bucket 10 (1024, 704): 1\n",
            "bucket 11 (1024, 768): 3\n",
            "bucket 12 (1024, 832): 4\n",
            "bucket 13 (1024, 960): 3\n",
            "bucket 14 (1024, 1024): 1\n",
            "mean ar error: 0.008918692303261123\n",
            "writing metadata: /content/LoRA/meta_lat.json\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# @title ## **3.4. Bucketing and Latents Caching**\n",
        "%store -r\n",
        "\n",
        "# @markdown This code will create buckets based on the `bucket_resolution` provided for multi-aspect ratio training, and then convert all images within the `train_data_dir` to latents.\n",
        "bucketing_json    = os.path.join(training_dir, \"meta_lat.json\")\n",
        "metadata_json     = os.path.join(training_dir, \"meta_clean.json\")\n",
        "bucket_resolution = 1024  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "mixed_precision   = \"no\"  # @param [\"no\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "skip_existing     = False  # @param{type:\"boolean\"}\n",
        "flip_aug          = False  # @param{type:\"boolean\"}\n",
        "# @markdown Use `clean_caption` option to clean such as duplicate tags, `women` to `girl`, etc\n",
        "clean_caption     = False #@param {type:\"boolean\"}\n",
        "#@markdown Use the `recursive` option to process subfolders as well\n",
        "recursive         = True #@param {type:\"boolean\"}\n",
        "\n",
        "metadata_config = {\n",
        "    \"_train_data_dir\": train_data_dir,\n",
        "    \"_out_json\": metadata_json,\n",
        "    \"recursive\": recursive,\n",
        "    \"full_path\": recursive,\n",
        "    \"clean_caption\": clean_caption\n",
        "}\n",
        "\n",
        "bucketing_config = {\n",
        "    \"_train_data_dir\": train_data_dir,\n",
        "    \"_in_json\": metadata_json,\n",
        "    \"_out_json\": bucketing_json,\n",
        "    \"_model_name_or_path\": vae_path if vae_path else model_path,\n",
        "    \"recursive\": recursive,\n",
        "    \"full_path\": recursive,\n",
        "    \"flip_aug\": flip_aug,\n",
        "    \"skip_existing\": skip_existing,\n",
        "    \"batch_size\": 4,\n",
        "    \"max_data_loader_n_workers\": 2,\n",
        "    \"max_resolution\": f\"{bucket_resolution}, {bucket_resolution}\",\n",
        "    \"mixed_precision\": mixed_precision,\n",
        "}\n",
        "\n",
        "def generate_args(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "    return args.strip()\n",
        "\n",
        "merge_metadata_args = generate_args(metadata_config)\n",
        "prepare_buckets_args = generate_args(bucketing_config)\n",
        "\n",
        "merge_metadata_command = f\"python merge_all_to_metadata.py {merge_metadata_args}\"\n",
        "prepare_buckets_command = f\"python prepare_buckets_latents.py {prepare_buckets_args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{merge_metadata_command}\n",
        "time.sleep(1)\n",
        "!{prepare_buckets_command}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZVkLuaRJ9e"
      },
      "source": [
        "# **IV. Training**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "cJgLfRtlHSjw",
        "outputId": "080e5683-3452-4e49-b326-50ffae07b509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 32\n",
            "network_alpha = 16\n",
            "network_args = [ \"conv_dim=32\", \"conv_alpha=16\",]\n",
            "network_train_unet_only = true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import toml\n",
        "\n",
        "# @title ## **4.1. LoRa: Low-Rank Adaptation Config**\n",
        "# @markdown Kohya's `LoRA` renamed to `LoRA-LierLa` and Kohya's `LoCon` renamed to `LoRA-C3Lier`, read [official announcement](https://github.com/kohya-ss/sd-scripts/blob/849bc24d205a35fbe1b2a4063edd7172533c1c01/README.md#naming-of-lora).\n",
        "network_category = \"LoRA_C3Lier\"  # @param [\"LoRA_LierLa\", \"LoRA_C3Lier\", \"DyLoRA_LierLa\", \"DyLoRA_C3Lier\", \"LoCon\", \"LoHa\", \"IA3\", \"LoKR\", \"DyLoRA_Lycoris\"]\n",
        "\n",
        "# @markdown | network_category | network_dim | network_alpha | conv_dim | conv_alpha | unit |\n",
        "# @markdown | :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "# @markdown | LoRA-LierLa | 32 | 1 | - | - | - |\n",
        "# @markdown | LoCon/LoRA-C3Lier | 16 | 8 | 8 | 1 | - |\n",
        "# @markdown | LoHa | 8 | 4 | 4 | 1 | - |\n",
        "# @markdown | Other Category | ? | ? | ? | ? | - |\n",
        "\n",
        "# @markdown Specify `network_args` to add `optional` training args, like for specifying each 25 block weight, read [this](https://github.com/kohya-ss/sd-scripts/blob/main/train_network_README-ja.md#%E9%9A%8E%E5%B1%A4%E5%88%A5%E5%AD%A6%E7%BF%92%E7%8E%87)\n",
        "network_args    = \"\"  # @param {'type':'string'}\n",
        "\n",
        "# @markdown ### **Linear Layer Config**\n",
        "# @markdown Used by all `network_category`. When in doubt, set `network_dim = network_alpha`\n",
        "network_dim     = 32  # @param {'type':'number'}\n",
        "network_alpha   = 16  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **Convolutional Layer Config**\n",
        "# @markdown Only required if `network_category` is not `LoRA_LierLa`, as it involves training convolutional layers in addition to linear layers.\n",
        "conv_dim        = 32  # @param {'type':'number'}\n",
        "conv_alpha      = 16  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **DyLoRA Config**\n",
        "# @markdown Only required if `network_category` is `DyLoRA_LierLa` and `DyLoRA_C3Lier`\n",
        "unit = 4  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(network_args, str):\n",
        "    network_args = network_args.strip()\n",
        "    if network_args.startswith('[') and network_args.endswith(']'):\n",
        "        try:\n",
        "            network_args = ast.literal_eval(network_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing network_args: {e}\\n\")\n",
        "            network_args = []\n",
        "    elif len(network_args) > 0:\n",
        "        print(f\"WARNING! '{network_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        network_args = []\n",
        "    else:\n",
        "        network_args = []\n",
        "else:\n",
        "    network_args = []\n",
        "\n",
        "network_config = {\n",
        "    \"LoRA_LierLa\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : []\n",
        "    },\n",
        "    \"LoRA_C3Lier\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_LierLa\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_C3Lier\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\",\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoCon\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=locon\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoHa\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=loha\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"IA3\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=ia3\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoKR\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=lokr\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_Lycoris\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=dylora\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "network_module = network_config[network_category][\"module\"]\n",
        "network_args.extend(network_config[network_category][\"args\"])\n",
        "\n",
        "lora_config = {\n",
        "    \"additional_network_arguments\": {\n",
        "        \"no_metadata\"                     : False,\n",
        "        \"network_module\"                  : network_module,\n",
        "        \"network_dim\"                     : network_dim,\n",
        "        \"network_alpha\"                   : network_alpha,\n",
        "        \"network_args\"                    : network_args,\n",
        "        \"network_train_unet_only\"         : True,\n",
        "        \"training_comment\"                : None,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(toml.dumps(lora_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "JNlw3u8arwir",
        "outputId": "219ac029-57ae-4225-9b90-663c1801ebe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdaFactor\"\n",
            "learning_rate = 0.0005\n",
            "max_grad_norm = 0\n",
            "optimizer_args = [ \"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\",]\n",
            "lr_scheduler = \"cosine_with_restarts\"\n",
            "lr_warmup_steps = 100\n",
            "lr_scheduler_num_cycles = 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import toml\n",
        "import ast\n",
        "\n",
        "# @title ## **4.2. Optimizer Config**\n",
        "# @markdown Use `Adafactor` optimizer. `RMSprop 8bit` or `Adagrad 8bit` may work. `AdamW 8bit` doesn't seem to work.\n",
        "optimizer_type = \"AdaFactor\"  # @param [\"AdamW\", \"AdamW8bit\", \"Lion8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation(DAdaptAdamPreprint)\", \"DAdaptAdaGrad\", \"DAdaptAdam\", \"DAdaptAdan\", \"DAdaptAdanIP\", \"DAdaptLion\", \"DAdaptSGD\", \"AdaFactor\"]\n",
        "# @markdown Specify `optimizer_args` to add `additional` args for optimizer, e.g: `[\"weight_decay=0.6\"]`\n",
        "optimizer_args = \"[ \\\"scale_parameter=False\\\", \\\"relative_step=False\\\", \\\"warmup_init=False\\\" ]\"  # @param {'type':'string'}\n",
        "# @markdown ### **Learning Rate Config**\n",
        "# @markdown Different `optimizer_type` and `network_category` for some condition requires different learning rate. It's recommended to set `text_encoder_lr = 1/2 * unet_lr`\n",
        "learning_rate = 5e-4  # @param {'type':'number'}\n",
        "# @markdown ### **LR Scheduler Config**\n",
        "# @markdown `lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs.\n",
        "lr_scheduler = \"cosine_with_restarts\"  # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"] {allow-input: false}\n",
        "lr_warmup_steps = 100  # @param {'type':'number'}\n",
        "# @markdown Specify `lr_scheduler_num` with `num_cycles` value for `cosine_with_restarts` or `power` value for `polynomial`\n",
        "lr_scheduler_num = 0  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(optimizer_args, str):\n",
        "    optimizer_args = optimizer_args.strip()\n",
        "    if optimizer_args.startswith('[') and optimizer_args.endswith(']'):\n",
        "        try:\n",
        "            optimizer_args = ast.literal_eval(optimizer_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing optimizer_args: {e}\\n\")\n",
        "            optimizer_args = []\n",
        "    elif len(optimizer_args) > 0:\n",
        "        print(f\"WARNING! '{optimizer_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        optimizer_args = []\n",
        "    else:\n",
        "        optimizer_args = []\n",
        "else:\n",
        "    optimizer_args = []\n",
        "\n",
        "optimizer_config = {\n",
        "    \"optimizer_arguments\": {\n",
        "        \"optimizer_type\"          : optimizer_type,\n",
        "        \"learning_rate\"           : learning_rate,\n",
        "        \"max_grad_norm\"           : 0,\n",
        "        \"optimizer_args\"          : optimizer_args,\n",
        "        \"lr_scheduler\"            : lr_scheduler,\n",
        "        \"lr_warmup_steps\"         : lr_warmup_steps,\n",
        "        \"lr_scheduler_num_cycles\" : lr_scheduler_num if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\"      : lr_scheduler_num if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_scheduler_type\"       : None,\n",
        "        \"lr_scheduler_args\"       : None,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(toml.dumps(optimizer_config))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YOxNM0x7dvfO"
      },
      "outputs": [],
      "source": [
        "# @title ## **4.3. Advanced Training Config** (Optional)\n",
        "import toml\n",
        "\n",
        "\n",
        "# @markdown ### **Optimizer State Config**\n",
        "save_optimizer_state      = False #@param {type:\"boolean\"}\n",
        "load_optimizer_state      = \"\" #@param {type:\"string\"}\n",
        "# @markdown ### **Noise Control**\n",
        "noise_control_type        = \"none\" #@param [\"none\", \"noise_offset\", \"multires_noise\"]\n",
        "# @markdown #### **a. Noise Offset**\n",
        "# @markdown Control and easily generating darker or light images by offset the noise when fine-tuning the model. Recommended value: `0.1`. Read [Diffusion With Offset Noise](https://www.crosslabs.org//blog/diffusion-with-offset-noise)\n",
        "noise_offset_num          = 0.0357  # @param {type:\"number\"}\n",
        "# @markdown **[Experimental]**\n",
        "# @markdown Automatically adjusts the noise offset based on the absolute mean values of each channel in the latents when used with `--noise_offset`. Specify a value around 1/10 to the same magnitude as the `--noise_offset` for best results. Set `0` to disable.\n",
        "adaptive_noise_scale      = 0.00357 # @param {type:\"number\"}\n",
        "# @markdown #### **b. Multires Noise**\n",
        "# @markdown enable multires noise with this number of iterations (if enabled, around 6-10 is recommended)\n",
        "multires_noise_iterations = 6 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "multires_noise_discount = 0.3 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "# @markdown ### **Caption Dropout**\n",
        "caption_dropout_rate = 0  # @param {type:\"number\"}\n",
        "caption_tag_dropout_rate = 0.5  # @param {type:\"number\"}\n",
        "caption_dropout_every_n_epochs = 0  # @param {type:\"number\"}\n",
        "# @markdown ### **Custom Train Function**\n",
        "# @markdown Gamma for reducing the weight of high-loss timesteps. Lower numbers have a stronger effect. The paper recommends `5`. Read the paper [here](https://arxiv.org/abs/2303.09556).\n",
        "min_snr_gamma             = 5 #@param {type:\"number\"}\n",
        "\n",
        "advanced_training_config = {\n",
        "    \"advanced_training_config\": {\n",
        "        \"resume\"                        : load_optimizer_state,\n",
        "        \"save_state\"                    : save_optimizer_state,\n",
        "        \"save_last_n_epochs_state\"      : save_optimizer_state,\n",
        "        \"noise_offset\"                  : noise_offset_num if noise_control_type == \"noise_offset\" else None,\n",
        "        \"adaptive_noise_scale\"          : adaptive_noise_scale if adaptive_noise_scale and noise_control_type == \"noise_offset\" else None,\n",
        "        \"multires_noise_iterations\"     : multires_noise_iterations if noise_control_type ==\"multires_noise\" else None,\n",
        "        \"multires_noise_discount\"       : multires_noise_discount if noise_control_type ==\"multires_noise\" else None,\n",
        "        \"caption_dropout_rate\"          : caption_dropout_rate,\n",
        "        \"caption_tag_dropout_rate\"      : caption_tag_dropout_rate,\n",
        "        \"caption_dropout_every_n_epochs\": caption_dropout_every_n_epochs,\n",
        "        \"min_snr_gamma\"                 : min_snr_gamma if not min_snr_gamma == -1 else None,\n",
        "    }\n",
        "}\n",
        "\n",
        "print(toml.dumps(advanced_training_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "-Z4w3lfFKLjr",
        "outputId": "ad10da3b-aad9-41b5-9f8e-73985eeab6bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[sdxl_arguments]\n",
            "cache_text_encoder_outputs = false\n",
            "no_half_vae = true\n",
            "min_timestep = 0\n",
            "max_timestep = 1000\n",
            "shuffle_caption = true\n",
            "lowram = true\n",
            "\n",
            "[model_arguments]\n",
            "pretrained_model_name_or_path = \"cagliostrolab/animagine-xl-3.0-base\"\n",
            "vae = \"/content/vae/sdxl_vae.safetensors\"\n",
            "\n",
            "[dataset_arguments]\n",
            "debug_dataset = false\n",
            "in_json = \"/content/LoRA/meta_lat.json\"\n",
            "train_data_dir = \"/content/LoRA/train_data\"\n",
            "dataset_repeats = 30\n",
            "keep_tokens = 0\n",
            "resolution = \"1024,1024\"\n",
            "color_aug = false\n",
            "token_warmup_min = 1\n",
            "token_warmup_step = 0\n",
            "\n",
            "[training_arguments]\n",
            "output_dir = \"/content/drive/MyDrive/kohya-trainer/output/lena_shinei_animagineb_xl_c3\"\n",
            "output_name = \"lena_shinei_animagineb_xl_c3\"\n",
            "save_precision = \"fp16\"\n",
            "save_every_n_epochs = 1\n",
            "train_batch_size = 4\n",
            "max_token_length = 225\n",
            "mem_eff_attn = false\n",
            "sdpa = true\n",
            "xformers = false\n",
            "max_train_epochs = 3\n",
            "max_data_loader_n_workers = 8\n",
            "persistent_data_loader_workers = true\n",
            "gradient_checkpointing = true\n",
            "gradient_accumulation_steps = 1\n",
            "mixed_precision = \"fp16\"\n",
            "\n",
            "[logging_arguments]\n",
            "log_with = \"wandb\"\n",
            "log_tracker_name = \"lena_shinei_animagineb_xl_c3\"\n",
            "logging_dir = \"/content/LoRA/logs\"\n",
            "\n",
            "[sample_prompt_arguments]\n",
            "sample_every_n_epochs = 1\n",
            "sample_sampler = \"euler_a\"\n",
            "\n",
            "[saving_arguments]\n",
            "save_model_as = \"safetensors\"\n",
            "\n",
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdaFactor\"\n",
            "learning_rate = 0.0005\n",
            "max_grad_norm = 0\n",
            "optimizer_args = [ \"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\",]\n",
            "lr_scheduler = \"cosine_with_restarts\"\n",
            "lr_warmup_steps = 100\n",
            "lr_scheduler_num_cycles = 0\n",
            "\n",
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 32\n",
            "network_alpha = 16\n",
            "network_args = [ \"conv_dim=32\", \"conv_alpha=16\",]\n",
            "network_train_unet_only = true\n",
            "\n",
            "\u001b[38;2;204;102;102mWARNING: This is not an error message, but the [advanced_training_config]\n",
            "dictionary is missing. Please run the '4.2. Advanced Training Config' cell if\n",
            "you intend to use it, or continue to the next step.\u001b[0m\n",
            "\n",
            "[prompt]\n",
            "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, \"\n",
            "width = 1024\n",
            "height = 1024\n",
            "scale = 12\n",
            "sample_steps = 28\n",
            "[[prompt.subset]]\n",
            "prompt = \"masterpiece, best quality, 1girl, lena, lena antenna hair, lena uniform, 1boy, shinei, eightysix jacket, hetero, couple, 86, sex, kissing, large insertion, cum, cum inside, exhibitionism, open mouth, eightysix basement, rape, anime coloring\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **4.4. Training Config**\n",
        "import toml\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown ### **Project Config**\n",
        "project_name                = \"lena_shinei_animagineb_xl_c3\"  # @param {type:\"string\"}\n",
        "# @markdown Get your `wandb_api_key` [here](https://wandb.ai/settings) to logs with wandb.\n",
        "wandb_api_key               = \"ecb23d01b24589d6de435db8f363bb9783a69ee5\" # @param {type:\"string\"}\n",
        "in_json                     = \"/content/LoRA/meta_lat.json\"  # @param {type:\"string\"}\n",
        "# @markdown ### **SDXL Config**\n",
        "gradient_checkpointing      = True  # @param {type:\"boolean\"}\n",
        "no_half_vae                 = True  # @param {type:\"boolean\"}\n",
        "#@markdown Recommended parameter for SDXL training but if you enable it, `shuffle_caption` won't work\n",
        "cache_text_encoder_outputs  = False  # @param {type:\"boolean\"}\n",
        "#@markdown These options can be used to train U-Net with different timesteps. The default values are 0 and 1000.\n",
        "min_timestep                = 0 # @param {type:\"number\"}\n",
        "max_timestep                = 1000 # @param {type:\"number\"}\n",
        "# @markdown ### **Dataset Config**\n",
        "num_repeats                 = 30  # @param {type:\"number\"}\n",
        "resolution                  = 1024  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "keep_tokens                 = 0  # @param {type:\"number\"}\n",
        "# @markdown ### **General Config**\n",
        "num_epochs                  = 3  # @param {type:\"number\"}\n",
        "train_batch_size            = 4  # @param {type:\"number\"}\n",
        "mixed_precision             = \"fp16\"  # @param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "seed                        = -1  # @param {type:\"number\"}\n",
        "optimization                = \"scaled dot-product attention\" # @param [\"xformers\", \"scaled dot-product attention\"]\n",
        "# @markdown ### **Save Output Config**\n",
        "save_precision              = \"fp16\"  # @param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs         = 1  # @param {type:\"number\"}\n",
        "# @markdown ### **Sample Prompt Config**\n",
        "enable_sample               = True  # @param {type:\"boolean\"}\n",
        "sampler                     = \"euler_a\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "positive_prompt             = \"\"\n",
        "negative_prompt             = \"\"\n",
        "quality_prompt              = \"NovelAI\"  # @param [\"None\", \"Waifu Diffusion 1.5\", \"NovelAI\", \"AbyssOrangeMix\", \"Stable Diffusion XL\"] {allow-input: false}\n",
        "if quality_prompt          == \"NovelAI\":\n",
        "    positive_prompt         = \"masterpiece, best quality, \"\n",
        "    negative_prompt         = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, \"\n",
        "if quality_prompt          == \"AbyssOrangeMix\":\n",
        "    positive_prompt         = \"masterpiece, best quality, \"\n",
        "    negative_prompt         = \"(worst quality, low quality:1.4), \"\n",
        "if quality_prompt          == \"Stable Diffusion XL\":\n",
        "    negative_prompt         = \"3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\"\n",
        "custom_prompt               = \"1girl, lena, lena antenna hair, lena uniform, 1boy, shinei, eightysix jacket, hetero, couple, 86, sex, kissing, large insertion, cum, cum inside, exhibitionism, open mouth, eightysix basement, rape, anime coloring\" # @param {type:\"string\"}\n",
        "# @markdown Specify `prompt_from_caption` if you want to use caption as prompt instead. Will be chosen randomly.\n",
        "prompt_from_caption         = \"none\"  # @param [\"none\", \".txt\", \".caption\"]\n",
        "if prompt_from_caption     != \"none\":\n",
        "    custom_prompt           = \"\"\n",
        "num_prompt                  = 2  # @param {type:\"number\"}\n",
        "logging_dir                 = os.path.join(training_dir, \"logs\")\n",
        "lowram                      = int(next(line.split()[1] for line in open('/proc/meminfo') if \"MemTotal\" in line)) / (1024**2) < 15\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "prompt_config = {\n",
        "    \"prompt\": {\n",
        "        \"negative_prompt\" : negative_prompt,\n",
        "        \"width\"           : resolution,\n",
        "        \"height\"          : resolution,\n",
        "        \"scale\"           : 12,\n",
        "        \"sample_steps\"    : 28,\n",
        "        \"subset\"          : [],\n",
        "    }\n",
        "}\n",
        "\n",
        "train_config = {\n",
        "    \"sdxl_arguments\": {\n",
        "        \"cache_text_encoder_outputs\" : cache_text_encoder_outputs,\n",
        "        \"no_half_vae\"                : True,\n",
        "        \"min_timestep\"               : min_timestep,\n",
        "        \"max_timestep\"               : max_timestep,\n",
        "        \"shuffle_caption\"            : True if not cache_text_encoder_outputs else False,\n",
        "        \"lowram\"                     : lowram\n",
        "    },\n",
        "    \"model_arguments\": {\n",
        "        \"pretrained_model_name_or_path\" : model_path,\n",
        "        \"vae\"                           : vae_path,\n",
        "    },\n",
        "    \"dataset_arguments\": {\n",
        "        \"debug_dataset\"                 : False,\n",
        "        \"in_json\"                       : in_json,\n",
        "        \"train_data_dir\"                : train_data_dir,\n",
        "        \"dataset_repeats\"               : num_repeats,\n",
        "        \"keep_tokens\"                   : keep_tokens,\n",
        "        \"resolution\"                    : str(resolution) + ',' + str(resolution),\n",
        "        \"color_aug\"                     : False,\n",
        "        \"face_crop_aug_range\"           : None,\n",
        "        \"token_warmup_min\"              : 1,\n",
        "        \"token_warmup_step\"             : 0,\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"output_dir\"                    : os.path.join(output_dir, project_name),\n",
        "        \"output_name\"                   : project_name if project_name else \"last\",\n",
        "        \"save_precision\"                : save_precision,\n",
        "        \"save_every_n_epochs\"           : save_every_n_epochs,\n",
        "        \"save_n_epoch_ratio\"            : None,\n",
        "        \"save_last_n_epochs\"            : None,\n",
        "        \"resume\"                        : None,\n",
        "        \"train_batch_size\"              : train_batch_size,\n",
        "        \"max_token_length\"              : 225,\n",
        "        \"mem_eff_attn\"                  : False,\n",
        "        \"sdpa\"                          : True if optimization == \"scaled dot-product attention\" else False,\n",
        "        \"xformers\"                      : True if optimization == \"xformers\" else False,\n",
        "        \"max_train_epochs\"              : num_epochs,\n",
        "        \"max_data_loader_n_workers\"     : 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"seed\"                          : seed if seed > 0 else None,\n",
        "        \"gradient_checkpointing\"        : gradient_checkpointing,\n",
        "        \"gradient_accumulation_steps\"   : 1,\n",
        "        \"mixed_precision\"               : mixed_precision,\n",
        "    },\n",
        "    \"logging_arguments\": {\n",
        "        \"log_with\"          : \"wandb\" if wandb_api_key else \"tensorboard\",\n",
        "        \"log_tracker_name\"  : project_name if wandb_api_key and not project_name == \"last\" else None,\n",
        "        \"logging_dir\"       : logging_dir,\n",
        "        \"log_prefix\"        : project_name if not wandb_api_key else None,\n",
        "    },\n",
        "    \"sample_prompt_arguments\": {\n",
        "        \"sample_every_n_steps\"    : None,\n",
        "        \"sample_every_n_epochs\"   : save_every_n_epochs if enable_sample else None,\n",
        "        \"sample_sampler\"          : sampler,\n",
        "    },\n",
        "    \"saving_arguments\": {\n",
        "        \"save_model_as\": \"safetensors\"\n",
        "    },\n",
        "}\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt):\n",
        "    if enable_sample:\n",
        "        search_pattern = os.path.join(train_data_dir, '**/*' + prompt_from_caption)\n",
        "        caption_files = glob.glob(search_pattern, recursive=True)\n",
        "\n",
        "        if not caption_files:\n",
        "            if not custom_prompt:\n",
        "                custom_prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\"\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = [\n",
        "                {\"prompt\": positive_prompt + custom_prompt if positive_prompt else custom_prompt}\n",
        "            ]\n",
        "        else:\n",
        "            selected_files = random.sample(caption_files, min(num_prompt, len(caption_files)))\n",
        "\n",
        "            prompts = []\n",
        "            for file in selected_files:\n",
        "                with open(file, 'r') as f:\n",
        "                    prompts.append(f.read().strip())\n",
        "\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = []\n",
        "\n",
        "            for prompt in prompts:\n",
        "                new_prompt = {\n",
        "                    \"prompt\": positive_prompt + prompt if positive_prompt else prompt,\n",
        "                }\n",
        "                new_prompt_config['prompt']['subset'].append(new_prompt)\n",
        "\n",
        "        return new_prompt_config\n",
        "    else:\n",
        "        return prompt_config\n",
        "\n",
        "def eliminate_none_variable(config):\n",
        "    for key in config:\n",
        "        if isinstance(config[key], dict):\n",
        "            for sub_key in config[key]:\n",
        "                if config[key][sub_key] == \"\":\n",
        "                    config[key][sub_key] = None\n",
        "        elif config[key] == \"\":\n",
        "            config[key] = None\n",
        "\n",
        "    return config\n",
        "\n",
        "try:\n",
        "    train_config.update(optimizer_config)\n",
        "except NameError:\n",
        "    raise NameError(\"'optimizer_config' dictionary is missing. Please run  '4.1. Optimizer Config' cell.\")\n",
        "\n",
        "try:\n",
        "    train_config.update(lora_config)\n",
        "except NameError:\n",
        "    raise NameError(\"'lora_config' dictionary is missing. Please run  '4.1. LoRa: Low-Rank Adaptation Config' cell.\")\n",
        "\n",
        "advanced_training_warning = False\n",
        "try:\n",
        "    train_config.update(advanced_training_config)\n",
        "except NameError:\n",
        "    advanced_training_warning = True\n",
        "    pass\n",
        "\n",
        "prompt_config = prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt)\n",
        "\n",
        "config_path         = os.path.join(config_dir, \"config_file.toml\")\n",
        "prompt_path         = os.path.join(config_dir, \"sample_prompt.toml\")\n",
        "\n",
        "config_str          = toml.dumps(eliminate_none_variable(train_config))\n",
        "prompt_str          = toml.dumps(eliminate_none_variable(prompt_config))\n",
        "\n",
        "write_file(config_path, config_str)\n",
        "write_file(prompt_path, prompt_str)\n",
        "\n",
        "print(config_str)\n",
        "\n",
        "if advanced_training_warning:\n",
        "    import textwrap\n",
        "    error_message = \"WARNING: This is not an error message, but the [advanced_training_config] dictionary is missing. Please run the '4.2. Advanced Training Config' cell if you intend to use it, or continue to the next step.\"\n",
        "    wrapped_message = textwrap.fill(error_message, width=80)\n",
        "    print('\\033[38;2;204;102;102m' + wrapped_message + '\\033[0m\\n')\n",
        "    pass\n",
        "\n",
        "print(prompt_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "p_SHtbFwHVl1",
        "outputId": "da404a8d-319d-4ebc-e9bc-9dac2f7537b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading settings from /content/LoRA/config/config_file.toml...\n",
            "/content/LoRA/config/config_file\n",
            "prepare tokenizers\n",
            "Downloading vocab.json: 100% 961k/961k [00:00<00:00, 7.52MB/s]\n",
            "Downloading merges.txt: 100% 525k/525k [00:00<00:00, 8.46MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 2.04MB/s]\n",
            "Downloading tokenizer_config.json: 100% 905/905 [00:00<00:00, 5.43MB/s]\n",
            "Downloading vocab.json: 100% 862k/862k [00:00<00:00, 6.91MB/s]\n",
            "Downloading merges.txt: 100% 525k/525k [00:00<00:00, 2.81MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 2.77MB/s]\n",
            "Downloading tokenizer_config.json: 100% 904/904 [00:00<00:00, 5.35MB/s]\n",
            "update token length: 225\n",
            "Training with captions.\n",
            "loading existing metadata: /content/LoRA/meta_lat.json\n",
            "metadata has bucket info, enable bucketing / メタデータにbucket情報があるためbucketを有効にします\n",
            "using bucket info in metadata / メタデータ内のbucket情報を使います\n",
            "[Dataset 0]\n",
            "  batch_size: 4\n",
            "  resolution: (1024, 1024)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: None\n",
            "  max_bucket_reso: None\n",
            "  bucket_reso_steps: None\n",
            "  bucket_no_upscale: None\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/LoRA/train_data\"\n",
            "    image_count: 61\n",
            "    num_repeats: 30\n",
            "    shuffle_caption: True\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    metadata_file: /content/LoRA/meta_lat.json\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 61/61 [00:00<00:00, 666282.67it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (384, 1024), count: 30\n",
            "bucket 1: resolution (512, 1024), count: 30\n",
            "bucket 2: resolution (576, 1024), count: 30\n",
            "bucket 3: resolution (640, 1024), count: 30\n",
            "bucket 4: resolution (704, 1024), count: 90\n",
            "bucket 5: resolution (832, 1024), count: 30\n",
            "bucket 6: resolution (896, 1024), count: 60\n",
            "bucket 7: resolution (960, 1024), count: 90\n",
            "bucket 8: resolution (1024, 512), count: 30\n",
            "bucket 9: resolution (1024, 576), count: 1050\n",
            "bucket 10: resolution (1024, 704), count: 30\n",
            "bucket 11: resolution (1024, 768), count: 90\n",
            "bucket 12: resolution (1024, 832), count: 120\n",
            "bucket 13: resolution (1024, 960), count: 90\n",
            "bucket 14: resolution (1024, 1024), count: 30\n",
            "mean ar error (without repeats): 0.0\n",
            "noise_offset is set to 0.0357 / noise_offsetが0.0357に設定されました\n",
            "preparing accelerator\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "loading model for process 0/1\n",
            "load Diffusers pretrained models: cagliostrolab/animagine-xl-3.0-base, variant=fp16\n",
            "Downloading model_index.json: 100% 577/577 [00:00<00:00, 2.74MB/s]\n",
            "Fetching 14 files:   0% 0/14 [00:00<?, ?it/s]\n",
            "Downloading (…)ncoder_2/config.json: 100% 570/570 [00:00<00:00, 2.78MB/s]\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 3.08MB/s]\n",
            "\n",
            "Downloading (…)_encoder/config.json: 100% 560/560 [00:00<00:00, 3.76MB/s]\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 855/855 [00:00<00:00, 4.34MB/s]\n",
            "\n",
            "Downloading (…)cheduler_config.json: 100% 474/474 [00:00<00:00, 3.18MB/s]\n",
            "Fetching 14 files:  14% 2/14 [00:00<00:04,  2.81it/s]\n",
            "Downloading unet/config.json: 100% 1.77k/1.77k [00:00<00:00, 11.5MB/s]\n",
            "\n",
            "Downloading tokenizer_2/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/1.39G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading vae/config.json: 100% 654/654 [00:00<00:00, 3.73MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   0% 0.00/5.14G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading tokenizer_2/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 4.53MB/s]\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   1% 10.5M/1.39G [00:00<00:35, 39.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   4% 10.5M/246M [00:00<00:05, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   0% 10.5M/5.14G [00:00<01:19, 64.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   2% 21.0M/1.39G [00:00<00:25, 54.4MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   6% 10.5M/167M [00:00<00:02, 76.2MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   2% 31.5M/1.39G [00:00<00:21, 64.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   9% 21.0M/246M [00:00<00:05, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   1% 31.5M/5.14G [00:00<00:59, 86.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   3% 41.9M/1.39G [00:00<00:19, 70.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   1% 41.9M/5.14G [00:00<01:00, 84.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  13% 31.5M/246M [00:00<00:04, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   1% 52.4M/5.14G [00:00<00:59, 86.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  13% 21.0M/167M [00:00<00:03, 41.4MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   4% 52.4M/1.39G [00:00<00:20, 64.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  17% 41.9M/246M [00:00<00:03, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   1% 62.9M/5.14G [00:00<00:59, 85.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  19% 31.5M/167M [00:00<00:02, 54.4MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   5% 62.9M/1.39G [00:00<00:19, 67.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  21% 52.4M/246M [00:00<00:03, 58.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   1% 73.4M/5.14G [00:00<00:58, 86.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  25% 41.9M/167M [00:00<00:02, 61.2MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   5% 73.4M/1.39G [00:01<00:17, 73.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   2% 83.9M/5.14G [00:00<00:59, 85.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  26% 62.9M/246M [00:01<00:03, 60.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   6% 83.9M/1.39G [00:01<00:17, 75.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  31% 52.4M/167M [00:00<00:01, 58.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   2% 94.4M/5.14G [00:01<01:00, 83.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  30% 73.4M/246M [00:01<00:02, 66.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   7% 94.4M/1.39G [00:01<00:16, 77.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  38% 62.9M/167M [00:01<00:01, 64.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   2% 105M/5.14G [00:01<00:59, 84.9MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  34% 83.9M/246M [00:01<00:02, 70.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   8% 105M/1.39G [00:01<00:16, 76.8MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   2% 115M/5.14G [00:01<00:58, 86.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  38% 94.4M/246M [00:01<00:02, 75.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  44% 73.4M/167M [00:01<00:01, 59.9MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   8% 115M/1.39G [00:01<00:16, 77.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   2% 126M/5.14G [00:01<00:58, 86.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  43% 105M/246M [00:01<00:01, 77.7MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   9% 126M/1.39G [00:01<00:16, 76.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   3% 136M/5.14G [00:01<00:58, 85.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  47% 115M/246M [00:01<00:01, 76.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  10% 136M/1.39G [00:01<00:15, 78.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   3% 147M/5.14G [00:01<00:59, 84.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  50% 83.9M/167M [00:01<00:01, 46.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  51% 126M/246M [00:01<00:01, 74.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   3% 157M/5.14G [00:01<00:58, 85.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  11% 147M/1.39G [00:02<00:16, 74.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  56% 94.4M/167M [00:01<00:01, 50.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  55% 136M/246M [00:02<00:01, 76.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   3% 168M/5.14G [00:01<01:00, 81.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  11% 157M/1.39G [00:02<00:17, 69.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  60% 147M/246M [00:02<00:01, 76.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   3% 178M/5.14G [00:02<00:59, 83.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  64% 157M/246M [00:02<00:01, 75.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  63% 105M/167M [00:02<00:01, 43.7MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   4% 189M/5.14G [00:02<01:07, 73.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  13% 178M/1.39G [00:02<00:16, 73.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  68% 168M/246M [00:02<00:01, 72.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  14% 189M/1.39G [00:02<00:15, 78.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   4% 199M/5.14G [00:02<01:04, 76.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   4% 210M/5.14G [00:02<00:59, 82.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  14% 199M/1.39G [00:02<00:14, 81.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  77% 189M/246M [00:02<00:00, 83.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  15% 210M/1.39G [00:02<00:13, 86.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   4% 220M/5.14G [00:02<00:57, 85.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  69% 115M/167M [00:02<00:01, 36.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  81% 199M/246M [00:02<00:00, 84.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  89% 220M/246M [00:03<00:00, 92.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  16% 220M/1.39G [00:03<00:19, 60.1MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  75% 126M/167M [00:02<00:01, 34.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   4% 231M/5.14G [00:02<01:28, 55.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  94% 231M/246M [00:03<00:00, 87.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  17% 231M/1.39G [00:03<00:17, 65.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  98% 241M/246M [00:03<00:00, 76.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  81% 136M/167M [00:03<00:00, 35.3MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  17% 241M/1.39G [00:03<00:19, 57.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.safetensors: 100% 246M/246M [00:03<00:00, 69.1MB/s]\n",
            "Fetching 14 files:  29% 4/14 [00:04<00:12,  1.25s/it]\n",
            "\n",
            "Downloading model.safetensors:  18% 252M/1.39G [00:03<00:19, 59.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   5% 262M/5.14G [00:03<01:20, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  88% 147M/167M [00:03<00:00, 35.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  19% 262M/1.39G [00:03<00:19, 58.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   5% 273M/5.14G [00:03<01:21, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  94% 157M/167M [00:03<00:00, 41.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   6% 283M/5.14G [00:03<01:13, 66.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  20% 273M/1.39G [00:03<00:17, 64.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   6% 294M/5.14G [00:03<01:06, 72.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  20% 283M/1.39G [00:04<00:15, 72.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  21% 294M/1.39G [00:04<00:13, 79.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   6% 304M/5.14G [00:03<01:03, 76.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors: 100% 167M/167M [00:03<00:00, 34.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   6% 325M/5.14G [00:04<00:54, 88.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors: 100% 167M/167M [00:04<00:00, 41.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   7% 336M/5.14G [00:04<00:52, 91.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  24% 336M/1.39G [00:04<00:10, 98.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   7% 346M/5.14G [00:04<00:53, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  26% 357M/1.39G [00:04<00:09, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   7% 367M/5.14G [00:04<00:47, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  27% 377M/1.39G [00:04<00:09, 104MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   8% 388M/5.14G [00:04<00:45, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading tokenizer_2/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading tokenizer_2/merges.txt: 100% 525k/525k [00:00<00:00, 839kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   8% 398M/5.14G [00:06<03:22, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  29% 398M/1.39G [00:07<00:52, 18.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   8% 409M/5.14G [00:07<04:49, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  29% 409M/1.39G [00:08<00:44, 22.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   8% 419M/5.14G [00:07<03:50, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  31% 430M/1.39G [00:08<00:30, 31.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  32% 440M/1.39G [00:09<00:44, 21.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   9% 440M/5.14G [00:09<04:10, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  32% 451M/1.39G [00:09<00:36, 25.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   9% 451M/5.14G [00:09<03:23, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  33% 461M/1.39G [00:10<00:55, 16.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   9% 461M/5.14G [00:10<04:59, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   9% 472M/5.14G [00:10<03:53, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  34% 472M/1.39G [00:10<00:43, 20.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  10% 493M/5.14G [00:10<02:27, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  35% 493M/1.39G [00:11<00:27, 32.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  10% 514M/5.14G [00:11<01:43, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  37% 514M/1.39G [00:11<00:19, 45.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  10% 535M/5.14G [00:11<01:17, 59.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  38% 535M/1.39G [00:11<00:14, 60.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  11% 556M/5.14G [00:11<01:01, 74.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  40% 556M/1.39G [00:11<00:10, 75.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  42% 577M/1.39G [00:11<00:08, 93.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  11% 577M/5.14G [00:11<00:51, 88.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  12% 598M/5.14G [00:11<00:44, 102MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  43% 598M/1.39G [00:11<00:07, 103MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  12% 619M/5.14G [00:11<00:37, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  45% 619M/1.39G [00:11<00:07, 105MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  12% 640M/5.14G [00:11<00:37, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  46% 640M/1.39G [00:12<00:07, 96.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  13% 661M/5.14G [00:12<00:41, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  48% 661M/1.39G [00:12<00:07, 91.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  13% 682M/5.14G [00:12<00:44, 99.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  49% 682M/1.39G [00:12<00:08, 85.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  14% 703M/5.14G [00:12<00:47, 93.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  50% 692M/1.39G [00:12<00:08, 84.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  51% 703M/1.39G [00:13<00:08, 84.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  14% 724M/5.14G [00:12<00:49, 90.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  51% 713M/1.39G [00:13<00:08, 83.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  14% 734M/5.14G [00:12<00:49, 88.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  52% 724M/1.39G [00:13<00:08, 82.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  14% 744M/5.14G [00:13<00:50, 87.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  53% 734M/1.39G [00:13<00:07, 82.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  15% 755M/5.14G [00:13<00:50, 87.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  15% 765M/5.14G [00:13<00:49, 87.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  54% 744M/1.39G [00:13<00:07, 81.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  15% 776M/5.14G [00:13<00:50, 86.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  54% 755M/1.39G [00:13<00:07, 81.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  15% 786M/5.14G [00:13<01:32, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  55% 765M/1.39G [00:14<00:25, 24.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  16% 797M/5.14G [00:16<06:04, 11.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  16% 818M/5.14G [00:16<03:34, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  56% 776M/1.39G [00:16<00:53, 11.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  16% 839M/5.14G [00:16<02:22, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  57% 797M/1.39G [00:17<00:30, 19.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  17% 860M/5.14G [00:17<01:44, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  17% 870M/5.14G [00:17<01:31, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  59% 818M/1.39G [00:17<00:20, 28.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  17% 891M/5.14G [00:17<01:12, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  60% 839M/1.39G [00:17<00:13, 39.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  18% 912M/5.14G [00:17<00:58, 72.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  62% 860M/1.39G [00:17<00:10, 52.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  63% 881M/1.39G [00:17<00:07, 66.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  18% 933M/5.14G [00:17<00:49, 85.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  19% 954M/5.14G [00:17<00:40, 102MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  65% 902M/1.39G [00:17<00:06, 80.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  19% 975M/5.14G [00:17<00:34, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  19% 996M/5.14G [00:17<00:30, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  66% 923M/1.39G [00:18<00:06, 69.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  20% 1.02G/5.14G [00:18<00:40, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  68% 944M/1.39G [00:20<00:21, 20.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  69% 954M/1.39G [00:21<00:23, 18.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  20% 1.04G/5.14G [00:21<03:46, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  70% 975M/1.39G [00:21<00:15, 27.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  20% 1.05G/5.14G [00:21<03:14, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  71% 986M/1.39G [00:21<00:12, 31.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  72% 996M/1.39G [00:22<00:10, 36.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  21% 1.07G/5.14G [00:21<02:19, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  73% 1.02G/1.39G [00:22<00:07, 50.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  21% 1.09G/5.14G [00:22<01:45, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  74% 1.03G/1.39G [00:22<00:06, 56.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  21% 1.10G/5.14G [00:22<01:32, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  75% 1.04G/1.39G [00:22<00:05, 61.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  22% 1.11G/5.14G [00:22<01:21, 49.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  75% 1.05G/1.39G [00:22<00:05, 65.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  22% 1.12G/5.14G [00:22<01:14, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  76% 1.06G/1.39G [00:22<00:04, 69.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  22% 1.13G/5.14G [00:22<01:06, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  77% 1.07G/1.39G [00:22<00:04, 68.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  22% 1.14G/5.14G [00:24<04:06, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  78% 1.08G/1.39G [00:26<00:35, 8.84MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  22% 1.15G/5.14G [00:26<06:25, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  79% 1.10G/1.39G [00:26<00:19, 15.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  23% 1.17G/5.14G [00:26<04:00, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  80% 1.11G/1.39G [00:27<00:15, 18.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  23% 1.18G/5.14G [00:27<03:23, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  81% 1.12G/1.39G [00:27<00:12, 21.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  82% 1.13G/1.39G [00:27<00:09, 26.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  23% 1.21G/5.14G [00:27<02:15, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  24% 1.22G/5.14G [00:27<01:56, 33.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  83% 1.15G/1.39G [00:27<00:05, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  85% 1.17G/1.39G [00:27<00:04, 53.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  24% 1.24G/5.14G [00:27<01:26, 45.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  25% 1.26G/5.14G [00:27<01:03, 60.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  86% 1.20G/1.39G [00:27<00:02, 69.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  88% 1.22G/1.39G [00:28<00:02, 78.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  25% 1.28G/5.14G [00:27<00:55, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  25% 1.29G/5.14G [00:28<00:52, 73.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  89% 1.24G/1.39G [00:28<00:01, 83.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  25% 1.30G/5.14G [00:28<00:52, 72.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  90% 1.25G/1.39G [00:28<00:01, 85.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  26% 1.31G/5.14G [00:28<00:49, 76.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  91% 1.26G/1.39G [00:28<00:01, 88.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  26% 1.33G/5.14G [00:28<00:38, 98.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  92% 1.28G/1.39G [00:28<00:01, 103MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  26% 1.35G/5.14G [00:28<00:34, 109MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  94% 1.30G/1.39G [00:28<00:00, 102MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  27% 1.37G/5.14G [00:28<00:33, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  95% 1.32G/1.39G [00:29<00:00, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  27% 1.39G/5.14G [00:29<00:37, 99.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  97% 1.34G/1.39G [00:29<00:00, 84.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  97% 1.35G/1.39G [00:31<00:01, 23.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  28% 1.42G/5.14G [00:31<02:21, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  98% 1.36G/1.39G [00:31<00:00, 28.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  28% 1.43G/5.14G [00:32<03:25, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors: 100% 1.39G/1.39G [00:32<00:00, 42.4MB/s]\n",
            "Fetching 14 files:  43% 6/14 [00:33<00:58,  7.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  28% 1.44G/5.14G [00:32<02:49, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  28% 1.46G/5.14G [00:32<01:53, 32.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  29% 1.49G/5.14G [00:32<01:09, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  29% 1.51G/5.14G [00:34<01:59, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  30% 1.52G/5.14G [00:34<01:44, 34.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  30% 1.54G/5.14G [00:34<01:17, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  30% 1.56G/5.14G [00:34<00:58, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  31% 1.59G/5.14G [00:34<00:40, 86.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  32% 1.63G/5.14G [00:34<00:31, 113MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  32% 1.65G/5.14G [00:35<00:31, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  32% 1.67G/5.14G [00:35<00:38, 89.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  33% 1.69G/5.14G [00:35<00:45, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  33% 1.71G/5.14G [00:36<00:55, 62.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  33% 1.72G/5.14G [00:36<00:59, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  34% 1.73G/5.14G [00:36<01:03, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  34% 1.74G/5.14G [00:37<01:06, 51.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  34% 1.75G/5.14G [00:37<01:09, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  34% 1.76G/5.14G [00:37<01:10, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  35% 1.77G/5.14G [00:37<01:11, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  35% 1.78G/5.14G [00:38<01:13, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  35% 1.79G/5.14G [00:38<01:11, 46.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  35% 1.80G/5.14G [00:38<01:11, 46.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  35% 1.81G/5.14G [00:38<01:12, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  36% 1.82G/5.14G [00:38<01:11, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  36% 1.84G/5.14G [00:39<01:10, 46.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  36% 1.85G/5.14G [00:39<01:10, 46.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  36% 1.86G/5.14G [00:39<01:09, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  36% 1.87G/5.14G [00:39<01:09, 47.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  37% 1.88G/5.14G [00:40<01:09, 46.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  37% 1.89G/5.14G [00:40<01:07, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  37% 1.90G/5.14G [00:40<01:08, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  37% 1.91G/5.14G [00:40<01:07, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  37% 1.92G/5.14G [00:40<01:07, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  38% 1.93G/5.14G [00:41<01:05, 48.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  38% 1.94G/5.14G [00:41<01:07, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  38% 1.95G/5.14G [00:41<01:04, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  38% 1.96G/5.14G [00:41<01:05, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  38% 1.97G/5.14G [00:41<01:04, 48.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  39% 1.98G/5.14G [00:42<01:05, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  39% 1.99G/5.14G [00:42<01:04, 48.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  39% 2.00G/5.14G [00:42<01:05, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  39% 2.01G/5.14G [00:42<01:04, 48.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  39% 2.02G/5.14G [00:43<01:09, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  40% 2.03G/5.14G [00:43<01:07, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  40% 2.04G/5.14G [00:43<01:05, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  40% 2.06G/5.14G [00:43<01:05, 46.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  40% 2.07G/5.14G [00:43<01:03, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  40% 2.08G/5.14G [00:44<00:59, 51.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  41% 2.09G/5.14G [00:44<01:00, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  41% 2.10G/5.14G [00:44<01:03, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  41% 2.11G/5.14G [00:44<01:11, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  41% 2.12G/5.14G [00:45<00:59, 50.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  41% 2.13G/5.14G [00:45<00:58, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  42% 2.14G/5.14G [00:45<01:01, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  42% 2.15G/5.14G [00:45<00:59, 50.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  42% 2.16G/5.14G [00:45<00:58, 50.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  42% 2.17G/5.14G [00:46<01:00, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  42% 2.18G/5.14G [00:46<00:58, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  43% 2.19G/5.14G [00:46<01:00, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  43% 2.20G/5.14G [00:46<00:59, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  43% 2.21G/5.14G [00:46<01:01, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  43% 2.22G/5.14G [00:47<00:58, 49.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  43% 2.23G/5.14G [00:47<01:00, 47.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  44% 2.24G/5.14G [00:47<00:58, 49.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  44% 2.25G/5.14G [00:47<01:00, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  44% 2.26G/5.14G [00:48<00:57, 49.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  44% 2.28G/5.14G [00:48<00:56, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  45% 2.29G/5.14G [00:48<00:58, 48.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  45% 2.30G/5.14G [00:48<00:56, 50.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  45% 2.31G/5.14G [00:48<00:59, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  45% 2.32G/5.14G [00:49<00:56, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  45% 2.33G/5.14G [00:49<00:58, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  46% 2.34G/5.14G [00:49<00:56, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  46% 2.35G/5.14G [00:49<00:55, 50.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  46% 2.36G/5.14G [00:49<00:57, 48.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  46% 2.37G/5.14G [00:50<00:55, 49.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  46% 2.38G/5.14G [00:50<00:57, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  47% 2.39G/5.14G [00:50<00:55, 49.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  47% 2.40G/5.14G [00:50<00:53, 50.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  47% 2.41G/5.14G [00:50<00:55, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  47% 2.42G/5.14G [00:51<00:54, 50.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  47% 2.43G/5.14G [00:51<00:52, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  48% 2.44G/5.14G [00:51<00:54, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  48% 2.45G/5.14G [00:51<00:52, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  48% 2.46G/5.14G [00:52<00:52, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  48% 2.47G/5.14G [00:52<00:53, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  48% 2.49G/5.14G [00:52<00:52, 50.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  49% 2.50G/5.14G [00:52<00:51, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  49% 2.51G/5.14G [00:52<00:50, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  49% 2.52G/5.14G [00:53<00:51, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  49% 2.53G/5.14G [00:53<00:50, 51.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  49% 2.54G/5.14G [00:53<00:49, 52.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  50% 2.55G/5.14G [00:53<00:53, 48.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  50% 2.56G/5.14G [00:53<00:55, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  50% 2.57G/5.14G [00:54<00:59, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  50% 2.58G/5.14G [00:54<01:00, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  50% 2.59G/5.14G [00:54<01:02, 41.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  51% 2.60G/5.14G [00:54<00:59, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  51% 2.61G/5.14G [00:55<00:59, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  51% 2.62G/5.14G [00:55<00:58, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  51% 2.63G/5.14G [00:55<00:56, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  51% 2.64G/5.14G [00:55<00:56, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  52% 2.65G/5.14G [00:56<00:56, 44.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  52% 2.66G/5.14G [00:56<00:55, 44.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  52% 2.67G/5.14G [00:56<00:54, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  52% 2.68G/5.14G [00:56<00:53, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  52% 2.69G/5.14G [00:57<00:52, 46.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  53% 2.71G/5.14G [00:57<00:51, 46.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  53% 2.72G/5.14G [00:57<00:50, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  53% 2.73G/5.14G [00:57<00:50, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  53% 2.74G/5.14G [00:57<00:49, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  53% 2.75G/5.14G [00:58<00:49, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  54% 2.76G/5.14G [00:58<00:48, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  54% 2.77G/5.14G [00:58<00:47, 49.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  54% 2.78G/5.14G [00:58<00:47, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  54% 2.79G/5.14G [00:58<00:46, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  55% 2.80G/5.14G [00:59<00:46, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  55% 2.81G/5.14G [00:59<00:46, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  55% 2.82G/5.14G [00:59<00:45, 50.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  55% 2.83G/5.14G [00:59<00:44, 51.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  55% 2.84G/5.14G [00:59<00:45, 50.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  56% 2.85G/5.14G [01:00<00:44, 51.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  56% 2.86G/5.14G [01:00<00:44, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  56% 2.87G/5.14G [01:00<00:43, 52.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  56% 2.88G/5.14G [01:00<00:43, 52.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  56% 2.89G/5.14G [01:00<00:43, 51.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  57% 2.90G/5.14G [01:01<00:42, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  57% 2.92G/5.14G [01:01<00:42, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  57% 2.93G/5.14G [01:01<00:41, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  57% 2.94G/5.14G [01:01<00:42, 52.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  57% 2.95G/5.14G [01:01<00:41, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  58% 2.96G/5.14G [01:02<00:41, 52.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  58% 2.97G/5.14G [01:02<00:40, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  58% 2.98G/5.14G [01:02<00:40, 53.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  58% 2.99G/5.14G [01:02<00:39, 53.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  58% 3.00G/5.14G [01:02<00:40, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  59% 3.01G/5.14G [01:03<00:40, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  59% 3.02G/5.14G [01:03<00:39, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  59% 3.03G/5.14G [01:03<00:39, 53.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  59% 3.04G/5.14G [01:03<00:38, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  59% 3.05G/5.14G [01:03<00:38, 54.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  60% 3.06G/5.14G [01:04<00:38, 53.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  60% 3.07G/5.14G [01:04<00:39, 52.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  60% 3.08G/5.14G [01:04<00:38, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  60% 3.09G/5.14G [01:04<00:38, 53.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  60% 3.10G/5.14G [01:04<00:38, 53.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  61% 3.11G/5.14G [01:05<00:39, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  61% 3.12G/5.14G [01:05<00:36, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  61% 3.14G/5.14G [01:05<00:37, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  61% 3.15G/5.14G [01:05<00:37, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  61% 3.16G/5.14G [01:05<00:40, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  62% 3.17G/5.14G [01:06<00:35, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  62% 3.18G/5.14G [01:06<00:35, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  62% 3.19G/5.14G [01:06<00:35, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  62% 3.20G/5.14G [01:06<00:36, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  62% 3.21G/5.14G [01:06<00:36, 53.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  63% 3.22G/5.14G [01:07<00:35, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  63% 3.23G/5.14G [01:07<00:35, 53.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  63% 3.24G/5.14G [01:07<00:44, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  64% 3.26G/5.14G [01:07<00:32, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  64% 3.27G/5.14G [01:08<00:33, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  64% 3.28G/5.14G [01:08<00:33, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  64% 3.29G/5.14G [01:08<00:33, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  64% 3.30G/5.14G [01:08<00:33, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  65% 3.31G/5.14G [01:08<00:33, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  65% 3.32G/5.14G [01:09<00:33, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  65% 3.33G/5.14G [01:09<00:33, 53.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  65% 3.34G/5.14G [01:09<00:33, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  65% 3.36G/5.14G [01:09<00:33, 53.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 3.37G/5.14G [01:09<00:32, 53.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 3.38G/5.14G [01:10<00:32, 54.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 3.39G/5.14G [01:10<00:32, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 3.40G/5.14G [01:10<00:31, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 3.41G/5.14G [01:10<00:31, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  67% 3.42G/5.14G [01:10<00:31, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  67% 3.43G/5.14G [01:10<00:31, 54.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  67% 3.44G/5.14G [01:11<00:31, 53.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  67% 3.45G/5.14G [01:11<00:31, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  67% 3.46G/5.14G [01:11<00:30, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  68% 3.47G/5.14G [01:11<00:30, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  68% 3.48G/5.14G [01:11<00:30, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  68% 3.49G/5.14G [01:12<00:29, 55.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  68% 3.50G/5.14G [01:12<00:29, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  68% 3.51G/5.14G [01:12<00:30, 53.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  69% 3.52G/5.14G [01:12<00:28, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  69% 3.53G/5.14G [01:12<00:28, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  69% 3.54G/5.14G [01:13<00:27, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  69% 3.55G/5.14G [01:13<00:27, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  69% 3.57G/5.14G [01:13<00:27, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  70% 3.58G/5.14G [01:13<00:26, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  70% 3.59G/5.14G [01:13<00:26, 58.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  70% 3.60G/5.14G [01:13<00:26, 58.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  70% 3.61G/5.14G [01:14<00:26, 58.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  70% 3.62G/5.14G [01:14<00:25, 58.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  71% 3.63G/5.14G [01:14<00:26, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  71% 3.64G/5.14G [01:14<00:25, 59.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  71% 3.65G/5.14G [01:14<00:24, 60.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  71% 3.66G/5.14G [01:14<00:24, 60.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  71% 3.67G/5.14G [01:15<00:24, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  72% 3.68G/5.14G [01:15<00:24, 60.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  72% 3.69G/5.14G [01:15<00:23, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  72% 3.70G/5.14G [01:15<00:23, 61.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  72% 3.71G/5.14G [01:15<00:23, 61.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  72% 3.72G/5.14G [01:15<00:22, 63.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  73% 3.73G/5.14G [01:16<00:22, 62.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  73% 3.74G/5.14G [01:16<00:25, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  73% 3.76G/5.14G [01:16<00:20, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  74% 3.77G/5.14G [01:16<00:20, 67.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  74% 3.79G/5.14G [01:16<00:20, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  74% 3.80G/5.14G [01:17<00:21, 61.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  74% 3.81G/5.14G [01:17<00:20, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  74% 3.82G/5.14G [01:17<00:18, 70.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 3.83G/5.14G [01:17<00:18, 69.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 3.84G/5.14G [01:17<00:18, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 3.85G/5.14G [01:17<00:18, 70.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 3.86G/5.14G [01:18<00:18, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 3.87G/5.14G [01:18<00:17, 71.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  76% 3.88G/5.14G [01:18<00:17, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  76% 3.89G/5.14G [01:18<00:17, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  76% 3.90G/5.14G [01:18<00:16, 72.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  76% 3.91G/5.14G [01:18<00:16, 73.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  76% 3.92G/5.14G [01:18<00:16, 72.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  77% 3.93G/5.14G [01:19<00:16, 73.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  77% 3.94G/5.14G [01:19<00:15, 74.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  77% 3.95G/5.14G [01:19<00:15, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  77% 3.96G/5.14G [01:19<00:15, 76.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  77% 3.97G/5.14G [01:19<00:15, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  78% 3.98G/5.14G [01:19<00:15, 75.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  78% 4.00G/5.14G [01:19<00:14, 77.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  78% 4.01G/5.14G [01:19<00:14, 79.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  78% 4.02G/5.14G [01:20<00:14, 79.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  78% 4.03G/5.14G [01:20<00:13, 80.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  79% 4.04G/5.14G [01:20<00:13, 81.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  79% 4.05G/5.14G [01:20<00:13, 81.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  79% 4.06G/5.14G [01:20<00:13, 82.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  79% 4.07G/5.14G [01:20<00:12, 83.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  79% 4.08G/5.14G [01:20<00:12, 83.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  80% 4.09G/5.14G [01:20<00:12, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  80% 4.10G/5.14G [01:21<00:12, 83.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  80% 4.11G/5.14G [01:21<00:12, 83.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  80% 4.12G/5.14G [01:21<00:12, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  80% 4.13G/5.14G [01:21<00:11, 83.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 4.14G/5.14G [01:21<00:11, 83.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 4.15G/5.14G [01:21<00:11, 83.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 4.16G/5.14G [01:21<00:11, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 4.17G/5.14G [01:21<00:11, 83.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 4.18G/5.14G [01:22<00:11, 83.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  82% 4.19G/5.14G [01:22<00:11, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  82% 4.20G/5.14G [01:23<00:41, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  82% 4.23G/5.14G [01:23<00:24, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  83% 4.26G/5.14G [01:23<00:13, 63.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  83% 4.28G/5.14G [01:23<00:10, 81.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  84% 4.30G/5.14G [01:23<00:08, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  84% 4.33G/5.14G [01:24<00:06, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  85% 4.35G/5.14G [01:24<00:05, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  85% 4.37G/5.14G [01:24<00:06, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  86% 4.39G/5.14G [01:24<00:07, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  86% 4.41G/5.14G [01:24<00:07, 95.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  86% 4.44G/5.14G [01:25<00:07, 94.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  87% 4.46G/5.14G [01:25<00:07, 90.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  87% 4.47G/5.14G [01:25<00:07, 89.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  87% 4.48G/5.14G [01:25<00:07, 88.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  87% 4.49G/5.14G [01:25<00:07, 86.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  88% 4.50G/5.14G [01:25<00:07, 86.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  88% 4.51G/5.14G [01:26<00:07, 86.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  88% 4.52G/5.14G [01:26<00:07, 85.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  88% 4.53G/5.14G [01:26<00:07, 85.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  88% 4.54G/5.14G [01:26<00:07, 84.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  89% 4.55G/5.14G [01:26<00:06, 84.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  89% 4.56G/5.14G [01:28<00:34, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  89% 4.57G/5.14G [01:28<00:25, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  89% 4.59G/5.14G [01:28<00:15, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  90% 4.60G/5.14G [01:28<00:13, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  90% 4.63G/5.14G [01:28<00:07, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  91% 4.67G/5.14G [01:29<00:04, 103MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  91% 4.69G/5.14G [01:29<00:04, 89.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  92% 4.71G/5.14G [01:29<00:04, 107MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  92% 4.73G/5.14G [01:29<00:03, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  93% 4.75G/5.14G [01:29<00:02, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  93% 4.77G/5.14G [01:30<00:03, 110MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  93% 4.79G/5.14G [01:30<00:03, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  94% 4.81G/5.14G [01:30<00:03, 95.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  94% 4.83G/5.14G [01:30<00:03, 88.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  94% 4.84G/5.14G [01:30<00:03, 87.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  95% 4.85G/5.14G [01:31<00:03, 86.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  95% 4.87G/5.14G [01:31<00:03, 85.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  95% 4.88G/5.14G [01:31<00:03, 84.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  95% 4.89G/5.14G [01:31<00:02, 84.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  95% 4.90G/5.14G [01:31<00:02, 84.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  96% 4.91G/5.14G [01:31<00:02, 84.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  96% 4.92G/5.14G [01:31<00:02, 84.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  96% 4.93G/5.14G [01:31<00:02, 83.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  96% 4.94G/5.14G [01:32<00:02, 83.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  96% 4.95G/5.14G [01:32<00:02, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  97% 4.96G/5.14G [01:32<00:02, 84.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  97% 4.97G/5.14G [01:33<00:06, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  97% 4.99G/5.14G [01:33<00:03, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  98% 5.01G/5.14G [01:33<00:02, 60.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  98% 5.04G/5.14G [01:33<00:00, 93.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  99% 5.08G/5.14G [01:33<00:00, 127MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  99% 5.11G/5.14G [01:34<00:00, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors: 100% 5.14G/5.14G [01:34<00:00, 54.4MB/s]\n",
            "Fetching 14 files: 100% 14/14 [01:35<00:00,  6.82s/it]\n",
            "The config attributes {'attention_type': 'default', 'dropout': 0.0, 'reverse_transformer_layers_per_block': None} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
            "The config attributes {'force_upcast': False} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
            "U-Net converted to original U-Net\n",
            "load VAE: /content/vae/sdxl_vae.safetensors\n",
            "additional VAE loaded\n",
            "Enable SDPA for U-Net\n",
            "import network module: networks.lora\n",
            "create LoRA network. base dim (rank): 32, alpha: 16\n",
            "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
            "apply LoRA to Conv2d with kernel size (3,3). dim (rank): 32, alpha: 16.0\n",
            "create LoRA for Text Encoder 1:\n",
            "create LoRA for Text Encoder 2:\n",
            "create LoRA for Text Encoder: 264 modules.\n",
            "create LoRA for U-Net: 788 modules.\n",
            "enable LoRA for U-Net\n",
            "prepare optimizer, data loader etc.\n",
            "use Adafactor optimizer | {'scale_parameter': False, 'relative_step': False, 'warmup_init': False}\n",
            "constant_with_warmup will be good / スケジューラはconstant_with_warmupが良いかもしれません\n",
            "override steps. steps for 3 epochs is / 指定エポックまでのステップ数: 1392\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 1830\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 464\n",
            "  num epochs / epoch数: 3\n",
            "  batch size per device / バッチサイズ: 4\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 1392\n",
            "steps:   0% 0/1392 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmilf-armpits\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.2 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/LoRA/logs/20240201072350/wandb/run-20240201_072611-pzmnlavl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvague-terrain-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/milf-armpits/lena_shinei_animagineb_xl_c3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/milf-armpits/lena_shinei_animagineb_xl_c3/runs/pzmnlavl\u001b[0m\n",
            "\n",
            "epoch 1/3\n",
            "steps:  33% 464/1392 [45:24<1:30:49,  5.87s/it, loss=0.0913]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/lena_shinei_animagineb_xl_c3/lena_shinei_animagineb_xl_c3-000001.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 464\n",
            "prompt: masterpiece, best quality, 1girl, lena, lena antenna hair, lena uniform, 1boy, shinei, eightysix jacket, hetero, couple, 86, sex, kissing, large insertion, cum, cum inside, exhibitionism, open mouth, eightysix basement, rape, anime coloring\n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, \n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:33,  1.25s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:31,  1.20s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.18s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:28,  1.18s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.17s/it]\u001b[A\n",
            " 21% 6/28 [00:07<00:25,  1.17s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.17s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.17s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.17s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.17s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.17s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.17s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.17s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.17s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.17s/it]\u001b[A\n",
            " 61% 17/28 [00:19<00:12,  1.17s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:11,  1.17s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.18s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.17s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.18s/it]\u001b[A\n",
            " 79% 22/28 [00:25<00:07,  1.18s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:05,  1.18s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.18s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.18s/it]\u001b[A\n",
            " 93% 26/28 [00:30<00:02,  1.18s/it]\u001b[A\n",
            " 96% 27/28 [00:31<00:01,  1.18s/it]\u001b[A\n",
            "100% 28/28 [00:32<00:00,  1.18s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 2/3\n",
            "steps:  67% 928/1392 [1:31:31<45:45,  5.92s/it, loss=0.0838]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/lena_shinei_animagineb_xl_c3/lena_shinei_animagineb_xl_c3-000002.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 928\n",
            "prompt: masterpiece, best quality, 1girl, lena, lena antenna hair, lena uniform, 1boy, shinei, eightysix jacket, hetero, couple, 86, sex, kissing, large insertion, cum, cum inside, exhibitionism, open mouth, eightysix basement, rape, anime coloring\n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, \n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:32,  1.22s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.19s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.18s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:28,  1.18s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:27,  1.18s/it]\u001b[A\n",
            " 21% 6/28 [00:07<00:25,  1.17s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.17s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.17s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.18s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.18s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.18s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.18s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.18s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:12,  1.18s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:11,  1.18s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.18s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.18s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.18s/it]\u001b[A\n",
            " 79% 22/28 [00:25<00:07,  1.18s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:05,  1.18s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.18s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.18s/it]\u001b[A\n",
            " 93% 26/28 [00:30<00:02,  1.18s/it]\u001b[A\n",
            " 96% 27/28 [00:31<00:01,  1.18s/it]\u001b[A\n",
            "100% 28/28 [00:32<00:00,  1.18s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 3/3\n",
            "steps: 100% 1392/1392 [2:17:42<00:00,  5.94s/it, loss=0.0845]\n",
            "generating sample images at step / サンプル画像生成 ステップ: 1392\n",
            "prompt: masterpiece, best quality, 1girl, lena, lena antenna hair, lena uniform, 1boy, shinei, eightysix jacket, hetero, couple, 86, sex, kissing, large insertion, cum, cum inside, exhibitionism, open mouth, eightysix basement, rape, anime coloring\n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, \n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:31,  1.18s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.17s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.17s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:28,  1.17s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:27,  1.17s/it]\u001b[A\n",
            " 21% 6/28 [00:07<00:25,  1.17s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.17s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.17s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.17s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.17s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.17s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.19s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.19s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.19s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:11,  1.18s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.18s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.18s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.18s/it]\u001b[A\n",
            " 79% 22/28 [00:25<00:07,  1.18s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:05,  1.18s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.18s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.18s/it]\u001b[A\n",
            " 93% 26/28 [00:30<00:02,  1.18s/it]\u001b[A\n",
            " 96% 27/28 [00:31<00:01,  1.18s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.18s/it]\u001b[A\n",
            "                                   \u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss/average █▇▄▆▆▆▆▆▆▆▆▆▅▅▄▅▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss/current ▁▅▃▅▄▆▅▆▃▅█▆▃▄▅▂█▅▂▂▇▆▁▆▇▃▂▂▄▃▃▄▄▂█▆▃▁▄▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      lr/unet ▂▄▇████████████████████████████████████▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss/average 0.0845\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss/current 0.05843\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      lr/unet 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvague-terrain-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/milf-armpits/lena_shinei_animagineb_xl_c3/runs/pzmnlavl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/milf-armpits/lena_shinei_animagineb_xl_c3/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzNTkyODQ1Ng==/version_details/v0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 3 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/content/LoRA/logs/20240201072350/wandb/run-20240201_072611-pzmnlavl/logs\u001b[0m\n",
            "\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/lena_shinei_animagineb_xl_c3/lena_shinei_animagineb_xl_c3.safetensors\n",
            "model saved.\n",
            "steps: 100% 1392/1392 [2:18:28<00:00,  5.97s/it, loss=0.0845]\n"
          ]
        }
      ],
      "source": [
        "#@title ## **4.5. Start Training**\n",
        "import os\n",
        "import toml\n",
        "\n",
        "#@markdown Check your config here if you want to edit something:\n",
        "#@markdown - `sample_prompt` : /content/LoRA/config/sample_prompt.toml\n",
        "#@markdown - `config_file` : /content/LoRA/config/config_file.toml\n",
        "\n",
        "\n",
        "#@markdown You can import config from another session if you want.\n",
        "\n",
        "sample_prompt   = \"/content/LoRA/config/sample_prompt.toml\" #@param {type:'string'}\n",
        "config_file     = \"/content/LoRA/config/config_file.toml\" #@param {type:'string'}\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def train(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : \"/content/kohya-trainer/accelerate_config/config.yaml\",\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\"  : sample_prompt if os.path.exists(sample_prompt) else None,\n",
        "    \"config_file\"     : config_file,\n",
        "    \"wandb_api_key\"   : wandb_api_key if wandb_api_key else None\n",
        "}\n",
        "\n",
        "accelerate_args = train(accelerate_conf)\n",
        "train_args = train(train_conf)\n",
        "\n",
        "final_args = f\"accelerate launch {accelerate_args} sdxl_train_network.py {train_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vhtDOMtG7qd"
      },
      "source": [
        "## V. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t4OhkX7Dz7CH"
      },
      "outputs": [],
      "source": [
        "#@title ## **5.1. Inference**\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# @markdown ### Model Config\n",
        "network_weights = \"\" #@param {type:'string'}\n",
        "network_mul = 0.7 # @param {type:\"slider\", min:-1, max:1, step:0.05}\n",
        "# @markdown ### Prompt Config\n",
        "prompt = \"face focus, cute, 1girl, green hair, sweater, looking at viewer, upper body, beanie, outdoors, night, turtleneck\" #@param {type:'string'}\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type:'string'}\n",
        "output_path = \"/content/tmp/\" #@param {type:'string'}\n",
        "resolution = \"1024, 1024\" # @param {type: \"string\"}\n",
        "optimization = \"scaled dot-product attention\" # @param [\"xformers\", \"scaled dot-product attention\"]\n",
        "conditional_resolution = \"1024, 1024\" # @param {type: \"string\"}\n",
        "steps = 28 # @param {type: \"number\"}\n",
        "sampler = \"euler_a\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "scale = 7 # @param {type: \"number\"}\n",
        "seed = -1 # @param {type: \"number\"}\n",
        "images_per_prompt = 1 # @param {type: \"number\"}\n",
        "batch_size = 1 # @param {type: \"number\"}\n",
        "clip_skip = 2 # @param {type: \"number\"}\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "separators = [\"*\", \"x\", \",\"]\n",
        "\n",
        "for separator in separators:\n",
        "    if separator in resolution:\n",
        "        width, height = [value.strip() for value in resolution.split(separator)]\n",
        "        original_width, original_height = [value.strip() for value in conditional_resolution.split(separator)]\n",
        "        break\n",
        "\n",
        "network_config = {\n",
        "    \"network_module\": network_module,\n",
        "    \"network_weights\": network_weights,\n",
        "    \"network_show_meta\": True,\n",
        "    \"network_mul\": network_mul,\n",
        "}\n",
        "\n",
        "config = {\n",
        "    \"prompt\": prompt + \" --n \" + negative_prompt,\n",
        "    \"images_per_prompt\": images_per_prompt,\n",
        "    \"outdir\": output_path,\n",
        "    \"W\": width,\n",
        "    \"H\": height,\n",
        "    \"original_width\": original_width,\n",
        "    \"original_height\": original_height,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"vae_batch_size\": 1,\n",
        "    \"no_half_vae\": True,\n",
        "    \"steps\": steps,\n",
        "    \"sampler\": sampler,\n",
        "    \"scale\": scale,\n",
        "    \"ckpt\": model_path,\n",
        "    \"vae\": vae_path,\n",
        "    \"seed\": seed if seed > 0 else None,\n",
        "    \"fp16\": True,\n",
        "    \"sdpa\": True if optimization == \"scaled dot-product attention\" else False,\n",
        "    \"xformers\": True if optimization == \"xformers\" else False,\n",
        "    \"opt_channels_last\": True,\n",
        "    \"clip_skip\": clip_skip,\n",
        "    \"max_embeddings_multiples\": 3,\n",
        "}\n",
        "\n",
        "if network_weights != \"\":\n",
        "    config.update(network_config)\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python sdxl_gen_img.py {args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyIl9BhNXKUq"
      },
      "source": [
        "# **VI. Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8YlP0cNQyujy",
        "outputId": "9b8c282c-65fb-408a-c275-a1a96185d955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "Model repo 'Ayane22/lena_shinei_animagineb_xl_c3' didn't exist, creating repo\n",
            "Model repo 'Ayane22/lena_shinei_animagineb_xl_c3' link: https://huggingface.co/Ayane22/lena_shinei_animagineb_xl_c3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **6.1. Huggingface Hub config**\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "# @markdown Login to Huggingface Hub\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"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\"  # @param {type:\"string\"}\n",
        "# @markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
        "orgs_name = \"\"  # @param{type:\"string\"}\n",
        "# @markdown If your model/dataset repo does not exist, it will automatically create it.\n",
        "model_name = project_name\n",
        "dataset_name = \"\"  # @param{type:\"string\"}\n",
        "make_private = True  # @param{type:\"boolean\"}\n",
        "\n",
        "def authenticate(write_token):\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "    api = HfApi()\n",
        "    return api.whoami(write_token), api\n",
        "\n",
        "def create_repo(api, user, orgs_name, repo_name, repo_type, make_private=False):\n",
        "    global model_repo\n",
        "    global datasets_repo\n",
        "\n",
        "    if orgs_name == \"\":\n",
        "        repo_id = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "    else:\n",
        "        repo_id = orgs_name + \"/\" + repo_name.strip()\n",
        "\n",
        "    try:\n",
        "        validate_repo_id(repo_id)\n",
        "        api.create_repo(repo_id=repo_id, repo_type=repo_type, private=make_private)\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' didn't exist, creating repo\")\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' exists, skipping create repo\")\n",
        "\n",
        "    if repo_type == \"model\":\n",
        "        model_repo = repo_id\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/{repo_id}\\n\")\n",
        "    else:\n",
        "        datasets_repo = repo_id\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/datasets/{repo_id}\\n\")\n",
        "\n",
        "user, api = authenticate(write_token)\n",
        "\n",
        "if model_name:\n",
        "    create_repo(api, user, orgs_name, model_name, \"model\", make_private)\n",
        "if dataset_name:\n",
        "    create_repo(api, user, orgs_name, dataset_name, \"dataset\", make_private)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# 압축하고자 하는 폴더의 경로\n",
        "folder_path = \"/content/LoRA/train_data\"  # 이 부분을 압축하고 싶은 폴더 경로로 바꿔주세요.\n",
        "# 압축 파일이 저장될 경로와 파일 이름 (확장자 없이)\n",
        "zip_file_path = \"/content/LoRA/train_data/lena_train_data\"  # 이 부분을 압축 파일의 경로와 이름으로 바꿔주세요.\n",
        "\n",
        "# 폴더를 zip 파일로 압축\n",
        "shutil.make_archive(zip_file_path, 'zip', folder_path)\n",
        "\n",
        "print(f\"'{Path(zip_file_path).name}.zip' has been created successfully at '{zip_file_path}.zip'\")"
      ],
      "metadata": {
        "id": "5gsC0PnAEclt",
        "outputId": "f5a95649-10b5-4e0b-adcb-d2f3a3cb1cd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'lena_train_data.zip' has been created successfully at '/content/LoRA/train_data/lena_train_data.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = zip_file_path"
      ],
      "metadata": {
        "id": "uJ0n8yVvFBnv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "8HpOZOglBJTz",
        "outputId": "570725f1-6797-4ebf-b3a7-6a0637caeed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b63afe7423a040b19c75ac2ca0401e54",
            "3b3c5edd31df4ad4a2a0797ba245ebe2",
            "c22a2a91bc0b498cb43b08ef89f40c42",
            "3d9fb60c8112474b846de75dfe60e9e9",
            "97402298097c4ac1ba810a047d236ea5",
            "76ff526e1fe2434c8c92f82e2b7062ab",
            "81fe557fb06d48fdb442cf772707c15d",
            "d243c3d2599b420eb6dcb6d59524f5da",
            "68f70a13bb5841df86b08ebb2c839ead",
            "c5b3efe8b9a3408eb97fda9e1c7223a6",
            "a718411454494beeb0a8ec69e2dfb192",
            "d1d8b820dcba4a049dec06bdc258f2d8",
            "e045f2eeebf74305bc23f9cd20c9c01b",
            "fc0cd3e3e0524f109ebb4a38ec3b91a5",
            "97780bdf742e48c381ee4e7784f84cf1",
            "34e68a4fabbe456a90731d6686271a75",
            "d1d55b99030444549e0ac85ef7876ec4",
            "fb3135d2fa1848e397306f153e3f9fee",
            "519e631e64fe4970b41189349dbc5870",
            "8d5d4c2cf7e149119ac93da095eec7aa",
            "0479ebe654bd4d138ad54497469d4ddb",
            "7a061a09d56d40b19ed0338739f5d411",
            "9f56564ae8434e378a11002043fbf85b",
            "ac6fb81c80364dc7bb62848768757497",
            "fd78e8e244804d238e46d0d51e0e9260",
            "eae3c38c1c264d69a0c0d302d4fd2993",
            "5e1c2ca0edcb4843b84abfe30aa63a6a",
            "6e036e6f09354aa58e77e4b835050fc2",
            "00f98d7905c24564b658ffef5760bf06",
            "5bea8bc72d244449b8695498a97315c2",
            "6de286c5884247a5aa549cb05900d2b5",
            "f3ff27b88f89443484ceef8e51aeba25",
            "60c97508d9204e9892af2a531ed658f9",
            "23313b92de594850af3abb6b2406c9e6",
            "5777f8f3a089439d95ebf81dd545e7a8",
            "9b6488f4723345aab83893d06894139b",
            "23013510d1b14ec49fb71505c1a4c80e",
            "1fd7e6674bae4450a34ad4495ad726c9",
            "567254e904f04ac0ac51b10694d8a5f1",
            "eb98f15c663b486abb5a5a938cd03327",
            "5613c7215d7a458687361d2d96560042",
            "8be3f237f0f34aa1bf213d670a958b19",
            "0409be562d6941b5824b9d7a7b0a898d",
            "33d6f16d49df43cab8398fa4ec56ebc3",
            "3224deed446846d88f9f3b0df1c1ea6c",
            "146f69dd7ad34debbd6e9b87fe9d2d3c",
            "6ad15ed1ae254eb8a0058451165c39a8",
            "92a4d891d812420294dc278646d30245",
            "34ec01c10c874ea5a5566a26d320d283",
            "c0f83f0380b94af6a581e0f47329801d",
            "84519da967a544c8836479462678f620",
            "f7a38af2eb984fe59c9459f3f9cc79d2",
            "a14b3b8b11754e07b11be0f924b2b7d6",
            "7481479e63214946bdf64b528a4abe98",
            "2b95492029e347eaaf88b200d790481a",
            "cb9c0e959eda47b1bc945752b593186f",
            "180b03c4d27a4374aa2daebecda1f16c",
            "2db52a65470a4084a185e94c7f48bcf6",
            "cfda89c0d74b42bb93f61a5fb4be7e93",
            "1505d750020a4b6c9fab5df51070ca25",
            "48f059d41727440c8dff0e836d7df977",
            "05eab975ec4941eab8c103430c8d3bb7",
            "0a3f508781524b318ce9eb37fe24f9dc",
            "1b42c4a8358f44d6b67bd0a9dffded38",
            "9235af6ebf704d29b9b686a8fa899bcc",
            "9fc747f3794a49e48d429e9f95bc6600",
            "39ba1f8f5da94a84b0ff260d3a682a14",
            "dbdd2afb241249a988dd47530b223031",
            "fe1d3da1e22f419c8556e3682806fd3e",
            "37a07dde8d8a4346bcf3b5bb9bc53cee",
            "fcf1ad97374e496bb938af3096e0f3de",
            "9d2e91cd4cc341678910b39e1a19491a",
            "a67f740065924a6b800f3816b2918157",
            "760a4e3f15954cf0b4d01735c62ef24b",
            "a1e66a765d4447ecb1df4870f6a45425",
            "91557be14dfb496a8af8838b3c5a0048",
            "9f1b9da0fe5b44ddb1b9bbb5951291db"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading lena_shinei_animagineb_xl_c3 to https://huggingface.co/Ayane22/lena_shinei_animagineb_xl_c3\n",
            "Please wait...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 6 LFS files:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b63afe7423a040b19c75ac2ca0401e54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "lena_shinei_animagineb_xl_c3_20240201081215_e000001_00.png:   0%|          | 0.00/1.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1d8b820dcba4a049dec06bdc258f2d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "lena_shinei_animagineb_xl_c3-000002.safetensors:   0%|          | 0.00/197M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f56564ae8434e378a11002043fbf85b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "lena_train_data.zip:   0%|          | 0.00/75.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23313b92de594850af3abb6b2406c9e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "lena_shinei_animagineb_xl_c3-000001.safetensors:   0%|          | 0.00/197M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3224deed446846d88f9f3b0df1c1ea6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "lena_shinei_animagineb_xl_c3.safetensors:   0%|          | 0.00/197M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb9c0e959eda47b1bc945752b593186f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "lena_shinei_animagineb_xl_c3_20240201085820_e000002_00.png:   0%|          | 0.00/1.01M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39ba1f8f5da94a84b0ff260d3a682a14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload success, located at https://huggingface.co/Ayane22/lena_shinei_animagineb_xl_c3/tree/main\n",
            "\n",
            "Uploading lena_shinei_animagineb_xl_c3_config to https://huggingface.co/Ayane22/lena_shinei_animagineb_xl_c3\n",
            "Please wait...\n",
            "Upload success, located at https://huggingface.co/Ayane22/lena_shinei_animagineb_xl_c3/tree/main\n",
            "\n",
            "Uploading lena_train_data to https://huggingface.co/Ayane22/lena_shinei_animagineb_xl_c3\n",
            "Please wait...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 82>\u001b[0m:\u001b[94m82\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mupload\u001b[0m:\u001b[94m80\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mupload_zip_to_model_repo\u001b[0m:\u001b[94m63\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m118\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, has_token=ha   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m118 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhf_api.py\u001b[0m:\u001b[94m826\u001b[0m in \u001b[92m_inner\u001b[0m                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 823 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.run_as_future(fn, \u001b[96mself\u001b[0m, *args, **kwargs)                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 824 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 825 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Otherwise, call the function normally\u001b[0m                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 826 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(\u001b[96mself\u001b[0m, *args, **kwargs)                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 827 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 828 \u001b[0m\u001b[2m│   \u001b[0m_inner.is_future_compatible = \u001b[94mTrue\u001b[0m  \u001b[2m# type: ignore\u001b[0m                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 829 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner  \u001b[2m# type: ignore\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhf_api.py\u001b[0m:\u001b[94m3200\u001b[0m in \u001b[92mupload_file\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3197 \u001b[0m\u001b[2m│   │   \u001b[0mcommit_message = (                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3198 \u001b[0m\u001b[2m│   │   │   \u001b[0mcommit_message \u001b[94mif\u001b[0m commit_message \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUpload \u001b[0m\u001b[33m{\u001b[0mpath_in_repo\u001b[33m}\u001b[0m\u001b[33m wi\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3199 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3200 \u001b[2m│   │   \u001b[0moperation = CommitOperationAdd(                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3201 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_fileobj=path_or_fileobj,                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3202 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_in_repo=path_in_repo,                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3203 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m5\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33m_commit_api.py\u001b[0m:\u001b[94m108\u001b[0m in \u001b[92m__post_init__\u001b[0m      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(\u001b[96mself\u001b[0m.path_or_fileobj, \u001b[96mstr\u001b[0m):                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_fileobj = os.path.normpath(os.path.expanduser(\u001b[96mself\u001b[0m.path_or_fileobj))   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m os.path.isfile(path_or_fileobj):                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m108 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mProvided path: \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpath_or_fileobj\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m is not a file on t\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(\u001b[96mself\u001b[0m.path_or_fileobj, (io.BufferedIOBase, \u001b[96mbytes\u001b[0m)):             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# ^^ Inspired from: https://stackoverflow.com/questions/44584829/how-to-dete\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mValueError: \u001b[0mProvided path: \u001b[32m'/content/LoRA/train_data/lena_train_data'\u001b[0m is not a file on the local file system\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 82&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">82</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">upload</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">80</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">upload_zip_to_model_repo</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">63</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">118</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> check_use_auth_token:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, has_token=ha   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>118 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _inner_fn  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hf_api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">826</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 823 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.run_as_future(fn, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 824 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 825 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Otherwise, call the function normally</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 826 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 827 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 828 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_inner.is_future_compatible = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 829 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _inner  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hf_api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">upload_file</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>commit_message = (                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>commit_message <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> commit_message <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #808000; text-decoration-color: #808000\">f\"Upload {</span>path_in_repo<span style=\"color: #808000; text-decoration-color: #808000\">} wi</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>operation = CommitOperationAdd(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3201 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>path_or_fileobj=path_or_fileobj,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3202 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>path_in_repo=path_in_repo,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3203 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_commit_api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">108</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__post_init__</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.path_or_fileobj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>path_or_fileobj = os.path.normpath(os.path.expanduser(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.path_or_fileobj))   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> os.path.isfile(path_or_fileobj):                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>108 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Provided path: '{</span>path_or_fileobj<span style=\"color: #808000; text-decoration-color: #808000\">}' is not a file on t</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.path_or_fileobj, (io.BufferedIOBase, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bytes</span>)):             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># ^^ Inspired from: https://stackoverflow.com/questions/44584829/how-to-dete</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Provided path: <span style=\"color: #008000; text-decoration-color: #008000\">'/content/LoRA/train_data/lena_train_data'</span> is not a file on the local file system\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title ## **6.2. Upload LoRA to Huggingface**\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "\n",
        "%store -r\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be uploaded to model repo\n",
        "model_path = \"/content/drive/MyDrive/kohya-trainer/output/lena_shinei_animagineb_xl_c3\"  # @param {type :\"string\"}\n",
        "path_in_repo = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown Now you can save your config file for future use\n",
        "config_path = \"/content/LoRA/config\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "    commit_message = f\"feat: upload {project_name} lora model\"\n",
        "\n",
        "def upload_to_hf(model_path, is_folder, is_config):\n",
        "    path_obj = Path(model_path)\n",
        "    trained_model = path_obj.parts[-1]\n",
        "\n",
        "    if path_in_repo:\n",
        "        trained_model = path_in_repo\n",
        "\n",
        "    if is_config:\n",
        "        trained_model = f\"{project_name}_config\"\n",
        "\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/{model_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    if is_folder:\n",
        "        api.upload_folder(\n",
        "            folder_path=model_path,\n",
        "            path_in_repo=trained_model,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/{model_repo}/tree/main\\n\")\n",
        "    else:\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=model_path,\n",
        "            path_in_repo=trained_model,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/{model_repo}/blob/main/{trained_model}\\n\")\n",
        "\n",
        "def upload_zip_to_model_repo(zip_path):\n",
        "    if not zip_path:\n",
        "        print(\"No zip file path provided.\")\n",
        "        return\n",
        "\n",
        "    zip_name = Path(zip_path).name\n",
        "\n",
        "    print(f\"Uploading {zip_name} to https://huggingface.co/{model_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=zip_path,\n",
        "        path_in_repo=zip_name,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=f\"feat: upload {zip_name}\"\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/{model_repo}/blob/main/{zip_name}\\n\")\n",
        "\n",
        "\n",
        "def upload():\n",
        "    is_model_file = model_path.endswith((\".ckpt\", \".safetensors\", \".pt\"))\n",
        "    upload_to_hf(model_path, not is_model_file, False)\n",
        "\n",
        "    if config_path:\n",
        "        upload_to_hf(config_path, True, True)\n",
        "\n",
        "    if zip_path:\n",
        "      upload_zip_to_model_repo(zip_path)\n",
        "\n",
        "upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IW-hS9jnmf-E"
      },
      "outputs": [],
      "source": [
        "# @title ## **6.3. Upload Dataset to Huggingface**\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be compressed to zip and  uploaded to datasets repo, leave it empty if not necessary\n",
        "train_data_path = \"/content/LoRA/train_data\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/LoRA/logs\"  # @param {type :\"string\"}\n",
        "\n",
        "tmp_dataset = f\"/content/LoRA/{project_name}_dataset\" if project_name else \"/content/LoRA/tmp_dataset\"\n",
        "tmp_train_data = f\"{tmp_dataset}/train_data\"\n",
        "dataset_zip = f\"{tmp_dataset}.zip\"\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "    commit_message = f\"feat: upload {project_name} dataset and logs\"\n",
        "\n",
        "os.makedirs(tmp_dataset, exist_ok=True)\n",
        "os.makedirs(tmp_train_data, exist_ok=True)\n",
        "\n",
        "def upload_dataset(dataset_path, is_zip):\n",
        "    path_obj = Path(dataset_path)\n",
        "    dataset_name = path_obj.parts[-1]\n",
        "\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/{datasets_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    if is_zip:\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=dataset_path,\n",
        "            path_in_repo=dataset_name,\n",
        "            repo_id=datasets_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/datasets/{datasets_repo}/blob/main/{dataset_name}\\n\")\n",
        "    else:\n",
        "        api.upload_folder(\n",
        "            folder_path=dataset_path,\n",
        "            path_in_repo=dataset_name,\n",
        "            repo_id=datasets_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/datasets/{datasets_repo}/tree/main/{dataset_name}\\n\")\n",
        "\n",
        "def zip_file(folder_path):\n",
        "    zip_path = f\"{folder_path}.zip\"\n",
        "    with zipfile.ZipFile(zip_path, \"w\") as zip_file:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                zip_file.write(os.path.join(root, file))\n",
        "\n",
        "def move(src_path, dst_path, move_metadata):\n",
        "    metadata_files = [\n",
        "        \"meta_cap.json\",\n",
        "        \"meta_cap_dd.json\",\n",
        "        \"meta_lat.json\",\n",
        "        \"meta_clean.json\",\n",
        "        \"meta_final.json\",\n",
        "    ]\n",
        "\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "    if move_metadata:\n",
        "        parent_meta_path = os.path.dirname(src_path)\n",
        "\n",
        "        for filename in os.listdir(parent_meta_path):\n",
        "            file_path = os.path.join(parent_meta_path, filename)\n",
        "            if filename in metadata_files:\n",
        "                shutil.move(file_path, dst_path)\n",
        "\n",
        "def upload():\n",
        "    if train_data_path:\n",
        "        move(train_data_path, tmp_train_data, False)\n",
        "        zip_file(tmp_dataset)\n",
        "        upload_dataset(dataset_zip, True)\n",
        "        os.remove(dataset_zip)\n",
        "    if logs_path:\n",
        "        upload_dataset(logs_path, False)\n",
        "\n",
        "upload()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b63afe7423a040b19c75ac2ca0401e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b3c5edd31df4ad4a2a0797ba245ebe2",
              "IPY_MODEL_c22a2a91bc0b498cb43b08ef89f40c42",
              "IPY_MODEL_3d9fb60c8112474b846de75dfe60e9e9"
            ],
            "layout": "IPY_MODEL_97402298097c4ac1ba810a047d236ea5"
          }
        },
        "3b3c5edd31df4ad4a2a0797ba245ebe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ff526e1fe2434c8c92f82e2b7062ab",
            "placeholder": "​",
            "style": "IPY_MODEL_81fe557fb06d48fdb442cf772707c15d",
            "value": "Upload 6 LFS files: 100%"
          }
        },
        "c22a2a91bc0b498cb43b08ef89f40c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d243c3d2599b420eb6dcb6d59524f5da",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68f70a13bb5841df86b08ebb2c839ead",
            "value": 6
          }
        },
        "3d9fb60c8112474b846de75dfe60e9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5b3efe8b9a3408eb97fda9e1c7223a6",
            "placeholder": "​",
            "style": "IPY_MODEL_a718411454494beeb0a8ec69e2dfb192",
            "value": " 6/6 [00:09&lt;00:00,  3.96s/it]"
          }
        },
        "97402298097c4ac1ba810a047d236ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ff526e1fe2434c8c92f82e2b7062ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81fe557fb06d48fdb442cf772707c15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d243c3d2599b420eb6dcb6d59524f5da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f70a13bb5841df86b08ebb2c839ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5b3efe8b9a3408eb97fda9e1c7223a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a718411454494beeb0a8ec69e2dfb192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1d8b820dcba4a049dec06bdc258f2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e045f2eeebf74305bc23f9cd20c9c01b",
              "IPY_MODEL_fc0cd3e3e0524f109ebb4a38ec3b91a5",
              "IPY_MODEL_97780bdf742e48c381ee4e7784f84cf1"
            ],
            "layout": "IPY_MODEL_34e68a4fabbe456a90731d6686271a75"
          }
        },
        "e045f2eeebf74305bc23f9cd20c9c01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1d55b99030444549e0ac85ef7876ec4",
            "placeholder": "​",
            "style": "IPY_MODEL_fb3135d2fa1848e397306f153e3f9fee",
            "value": "lena_shinei_animagineb_xl_c3_20240201081215_e000001_00.png: 100%"
          }
        },
        "fc0cd3e3e0524f109ebb4a38ec3b91a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_519e631e64fe4970b41189349dbc5870",
            "max": 1086350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d5d4c2cf7e149119ac93da095eec7aa",
            "value": 1086350
          }
        },
        "97780bdf742e48c381ee4e7784f84cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0479ebe654bd4d138ad54497469d4ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_7a061a09d56d40b19ed0338739f5d411",
            "value": " 1.09M/1.09M [00:00&lt;00:00, 35.3kB/s]"
          }
        },
        "34e68a4fabbe456a90731d6686271a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d55b99030444549e0ac85ef7876ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb3135d2fa1848e397306f153e3f9fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "519e631e64fe4970b41189349dbc5870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d5d4c2cf7e149119ac93da095eec7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0479ebe654bd4d138ad54497469d4ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a061a09d56d40b19ed0338739f5d411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f56564ae8434e378a11002043fbf85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac6fb81c80364dc7bb62848768757497",
              "IPY_MODEL_fd78e8e244804d238e46d0d51e0e9260",
              "IPY_MODEL_eae3c38c1c264d69a0c0d302d4fd2993"
            ],
            "layout": "IPY_MODEL_5e1c2ca0edcb4843b84abfe30aa63a6a"
          }
        },
        "ac6fb81c80364dc7bb62848768757497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e036e6f09354aa58e77e4b835050fc2",
            "placeholder": "​",
            "style": "IPY_MODEL_00f98d7905c24564b658ffef5760bf06",
            "value": "lena_shinei_animagineb_xl_c3-000002.safetensors: 100%"
          }
        },
        "fd78e8e244804d238e46d0d51e0e9260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bea8bc72d244449b8695498a97315c2",
            "max": 197092152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6de286c5884247a5aa549cb05900d2b5",
            "value": 197092152
          }
        },
        "eae3c38c1c264d69a0c0d302d4fd2993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3ff27b88f89443484ceef8e51aeba25",
            "placeholder": "​",
            "style": "IPY_MODEL_60c97508d9204e9892af2a531ed658f9",
            "value": " 197M/197M [00:08&lt;00:00, 31.2MB/s]"
          }
        },
        "5e1c2ca0edcb4843b84abfe30aa63a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e036e6f09354aa58e77e4b835050fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00f98d7905c24564b658ffef5760bf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bea8bc72d244449b8695498a97315c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de286c5884247a5aa549cb05900d2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3ff27b88f89443484ceef8e51aeba25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c97508d9204e9892af2a531ed658f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23313b92de594850af3abb6b2406c9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5777f8f3a089439d95ebf81dd545e7a8",
              "IPY_MODEL_9b6488f4723345aab83893d06894139b",
              "IPY_MODEL_23013510d1b14ec49fb71505c1a4c80e"
            ],
            "layout": "IPY_MODEL_1fd7e6674bae4450a34ad4495ad726c9"
          }
        },
        "5777f8f3a089439d95ebf81dd545e7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_567254e904f04ac0ac51b10694d8a5f1",
            "placeholder": "​",
            "style": "IPY_MODEL_eb98f15c663b486abb5a5a938cd03327",
            "value": "lena_train_data.zip: 100%"
          }
        },
        "9b6488f4723345aab83893d06894139b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5613c7215d7a458687361d2d96560042",
            "max": 75785768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8be3f237f0f34aa1bf213d670a958b19",
            "value": 75785768
          }
        },
        "23013510d1b14ec49fb71505c1a4c80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0409be562d6941b5824b9d7a7b0a898d",
            "placeholder": "​",
            "style": "IPY_MODEL_33d6f16d49df43cab8398fa4ec56ebc3",
            "value": " 75.8M/75.8M [00:04&lt;00:00, 33.7MB/s]"
          }
        },
        "1fd7e6674bae4450a34ad4495ad726c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567254e904f04ac0ac51b10694d8a5f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb98f15c663b486abb5a5a938cd03327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5613c7215d7a458687361d2d96560042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be3f237f0f34aa1bf213d670a958b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0409be562d6941b5824b9d7a7b0a898d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33d6f16d49df43cab8398fa4ec56ebc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3224deed446846d88f9f3b0df1c1ea6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_146f69dd7ad34debbd6e9b87fe9d2d3c",
              "IPY_MODEL_6ad15ed1ae254eb8a0058451165c39a8",
              "IPY_MODEL_92a4d891d812420294dc278646d30245"
            ],
            "layout": "IPY_MODEL_34ec01c10c874ea5a5566a26d320d283"
          }
        },
        "146f69dd7ad34debbd6e9b87fe9d2d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0f83f0380b94af6a581e0f47329801d",
            "placeholder": "​",
            "style": "IPY_MODEL_84519da967a544c8836479462678f620",
            "value": "lena_shinei_animagineb_xl_c3-000001.safetensors: 100%"
          }
        },
        "6ad15ed1ae254eb8a0058451165c39a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a38af2eb984fe59c9459f3f9cc79d2",
            "max": 197092152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a14b3b8b11754e07b11be0f924b2b7d6",
            "value": 197092152
          }
        },
        "92a4d891d812420294dc278646d30245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7481479e63214946bdf64b528a4abe98",
            "placeholder": "​",
            "style": "IPY_MODEL_2b95492029e347eaaf88b200d790481a",
            "value": " 197M/197M [00:08&lt;00:00, 23.4MB/s]"
          }
        },
        "34ec01c10c874ea5a5566a26d320d283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0f83f0380b94af6a581e0f47329801d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84519da967a544c8836479462678f620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7a38af2eb984fe59c9459f3f9cc79d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14b3b8b11754e07b11be0f924b2b7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7481479e63214946bdf64b528a4abe98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b95492029e347eaaf88b200d790481a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb9c0e959eda47b1bc945752b593186f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_180b03c4d27a4374aa2daebecda1f16c",
              "IPY_MODEL_2db52a65470a4084a185e94c7f48bcf6",
              "IPY_MODEL_cfda89c0d74b42bb93f61a5fb4be7e93"
            ],
            "layout": "IPY_MODEL_1505d750020a4b6c9fab5df51070ca25"
          }
        },
        "180b03c4d27a4374aa2daebecda1f16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48f059d41727440c8dff0e836d7df977",
            "placeholder": "​",
            "style": "IPY_MODEL_05eab975ec4941eab8c103430c8d3bb7",
            "value": "lena_shinei_animagineb_xl_c3.safetensors: 100%"
          }
        },
        "2db52a65470a4084a185e94c7f48bcf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a3f508781524b318ce9eb37fe24f9dc",
            "max": 197092152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b42c4a8358f44d6b67bd0a9dffded38",
            "value": 197092152
          }
        },
        "cfda89c0d74b42bb93f61a5fb4be7e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9235af6ebf704d29b9b686a8fa899bcc",
            "placeholder": "​",
            "style": "IPY_MODEL_9fc747f3794a49e48d429e9f95bc6600",
            "value": " 197M/197M [00:08&lt;00:00, 28.7MB/s]"
          }
        },
        "1505d750020a4b6c9fab5df51070ca25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48f059d41727440c8dff0e836d7df977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05eab975ec4941eab8c103430c8d3bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a3f508781524b318ce9eb37fe24f9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b42c4a8358f44d6b67bd0a9dffded38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9235af6ebf704d29b9b686a8fa899bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc747f3794a49e48d429e9f95bc6600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ba1f8f5da94a84b0ff260d3a682a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbdd2afb241249a988dd47530b223031",
              "IPY_MODEL_fe1d3da1e22f419c8556e3682806fd3e",
              "IPY_MODEL_37a07dde8d8a4346bcf3b5bb9bc53cee"
            ],
            "layout": "IPY_MODEL_fcf1ad97374e496bb938af3096e0f3de"
          }
        },
        "dbdd2afb241249a988dd47530b223031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d2e91cd4cc341678910b39e1a19491a",
            "placeholder": "​",
            "style": "IPY_MODEL_a67f740065924a6b800f3816b2918157",
            "value": "lena_shinei_animagineb_xl_c3_20240201085820_e000002_00.png: 100%"
          }
        },
        "fe1d3da1e22f419c8556e3682806fd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_760a4e3f15954cf0b4d01735c62ef24b",
            "max": 1010386,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1e66a765d4447ecb1df4870f6a45425",
            "value": 1010386
          }
        },
        "37a07dde8d8a4346bcf3b5bb9bc53cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91557be14dfb496a8af8838b3c5a0048",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1b9da0fe5b44ddb1b9bbb5951291db",
            "value": " 1.01M/1.01M [00:00&lt;00:00, 3.76MB/s]"
          }
        },
        "fcf1ad97374e496bb938af3096e0f3de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2e91cd4cc341678910b39e1a19491a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a67f740065924a6b800f3816b2918157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "760a4e3f15954cf0b4d01735c62ef24b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1e66a765d4447ecb1df4870f6a45425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91557be14dfb496a8af8838b3c5a0048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1b9da0fe5b44ddb1b9bbb5951291db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}